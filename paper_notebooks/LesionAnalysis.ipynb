{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCM, HVC Lesion Analysis\n",
    "\n",
    "This notebook is used to compute the statistics and generate figures presented in the [paper]. \n",
    "\n",
    "## 1 Reading the data\n",
    "\n",
    "Reading the data is facilitated by the class `zf_data.Tsvk`, which provides some helper methods to compute quantities used in the paper/figures. The name \"Tsvk\" refers to the term $T^{sv}_k$ from the methods used to compute $p(\\mathrm{int}|s,v,k)$ --- that is the probability that subject $s$ interrupts a particular vocalizer $v$, given that it has seen $k$ informative trials of that vocalizer. \n",
    "\n",
    "Note that this data structure is not required for any analyses, since the raw data can be loaded directly from `zebra-finch-memory-lesions/data/behavior/TrialData.csv` and processed however you choose. However, it can be far more convenient to use this structure since it predefines methods used to perform the analyses found in the paper.\n",
    "\n",
    "We also provide a helper functino `zf_data.load_trials()` for loading the TrialData.csv, which returns a pandas DataFrame containing all operant trials for all subjects.\n",
    "\n",
    "```python\n",
    "from zf_data import load_trials\n",
    "df = load_trials()\n",
    "```\n",
    "\n",
    "## 2 Using the Tsvk data structure\n",
    "\n",
    "A `Tsvk` instance is initialized with (1) a pandas DataFrame containing a filtered subset of operant trials, and (2) a value of `k_max`, the largest informative trial bin to include in the analysis.\n",
    "\n",
    "```python\n",
    "from zf_data import Tsvk\n",
    "tsvk = Tsvk(df[(df.LesionStage == \"prelesion\") & (df.VocalizerSet == \"S1\")], k_max=11)\n",
    "```\n",
    "\n",
    "### Methods\n",
    "\n",
    "Here are some of the helper methods `Tsvk` defines\n",
    "\n",
    "* `tsvk.p(subject, vocalizer, k)`\n",
    "    > Averages $p(\\mathrm{int}|s,v,k)$ over vocalizers. Use `Tsvk.re.p(...)` and `Tsvk.nore.p(...)` to restrict it to either Re or NoRe vocalizers respectively.\n",
    "\n",
    "* `tsvk.re.p_by_k()`, `Tsvk.nore.p_by_k()`\n",
    "    > for each $k$, estimates $p(\\mathrm{int}|Re,k)$ and $p(\\mathrm{int}|NoRe,k)$ by jackknifing over subjects. These are used to produce the group average learning curves in Figure 3A and 3B.\n",
    "\n",
    "* `tsvk.re.odds_by_subjects(k)`, `Tsvk.nore.odds_by_subjects(k)`\n",
    "    > for each $k$, computes odds of interrupting Re or NoRe vocalizers of each subject\n",
    "\n",
    "* `tsvk.logOR_by_subjects(k)`\n",
    "    > for each $k$, compute\n",
    "    $$\n",
    "    \\mathrm{logOR}(s, k)=\\mathrm{log}(Odds(\\mathrm{int}|s,NoRe,k)) - \\mathrm{log}(Odds(\\mathrm{int}|s,Re,k))\n",
    "    $$\n",
    "    for each subject, returning it in a pandas DataFrame\n",
    "\n",
    "* `tsvk.logOR()`\n",
    "    > Computes $\\mathrm{logOR}(k)$ for $k \\in \\{0, .., k_{max}\\}$. At each $k$, the estimate and SEM is estimated using a jackknife procedure over subjects, returning it in a pandas DataFrame. The condition $\\mathrm{logOR}(k) > 0$ is tested with a one-sided paired t-test over subjects. The Benjamini-Hochberg false discovery correction used in the paper should be applied after calling this method.\n",
    "\n",
    "* `tsvk.fisher_exact()`\n",
    "    > Computes the result of a Fisher exact test on the entire DataFrame, with the following contingency matrix. The Fisher exact test returns the estimate of $\\mathrm{OR}=\\frac{ad}{bc}$, 95% confidence bounds on the estimate, and a p-value. \n",
    "\n",
    "|         |Interruptions|Waits|\n",
    "|---------|:-:|:-:|\n",
    "|NoRe     | a | c |\n",
    "|Re       | b | d |\n",
    "\n",
    "### Note on caching results\n",
    "\n",
    "Computing the quantities used in the paper can be relatively slow (10s of seconds). Each `Tsvk` instance caches the result of most of its methods when they are called once, so that re-running a cell happens relatively instantaneously.\n",
    "\n",
    "Sometimes multiple figures/analyses operate on the same subset of data (e.g. the top and bottom figures of Figure 3A and 3B). To avoid re-instantiating a `Tsvk` instance for each analysis (which would cause all the computations to be re-run), a function called `get_or_create_Tsvk` is defined in this notebook which restores a previous `Tsvk` instance if the dataframe and k_max parameter are identical.\n",
    "\n",
    "## 3 Typical analysis pattern\n",
    "\n",
    "\n",
    "The pattern used in this notebook is usually:\n",
    "\n",
    "1. Instantiate a Tsvk object for one or more ranges of data (e.g. S1 & prelesion), e.g.\n",
    "\n",
    "```python\n",
    "tsvk = get_or_create_Tsvk(df[(df.LesionStage == \"prelesion\") & (df.VocalizerSet == \"S1\")], k_max=11)\n",
    "```\n",
    "\n",
    "2. Compute some quantity or quantities of interest, e.g.\n",
    "\n",
    "```python\n",
    "re_probabilities = tsvk.re.p_by_k()\n",
    "nore_probailities = tsvk.nore.p_by_k()\n",
    "```\n",
    "\n",
    "3. Plot or perform statistics on the returned quantities, e.g.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "plt.errorbar(re_probabilities.k, re_probabilities.logOR, y_err=2 * re_probabilities.SE)\n",
    "plt.errorbar(nore_probabilities.k, nore_probabilities.logOR, y_err=2 * nore_probabilities.SE)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qc7rtDVpVIfy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# TODO: create a setup.py instead of setting the path manually\n",
    "sys.path.append(\"/Users/kevin/Projects/theunissenlab/zebra-finch-memory-lesions/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FtM6Z9DnVaUz"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import scipy.stats\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "from zf_data import Tsvk, load_trials\n",
    "from zf_data.stats import false_discovery, likelihood_ratio_test\n",
    "from zf_data.plotting import (\n",
    "    border,\n",
    "    color_by_reward,\n",
    "    fig_grid,\n",
    "    smoothhist,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzrympcKFjGu"
   },
   "source": [
    "## Constants\n",
    "\n",
    "`K_MAX_INITIAL`: This determines how many informative trials we count when analyzing the initial response of a subject to a vocalizer. Since NoRe can be distinguished from Re after 2 or 3 informative trials, count only trials that occured up to and including `K_MAX_INITIAL=2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "F4xMWfQUFief"
   },
   "outputs": [],
   "source": [
    "SAVE_FIGS = True  #@param {type: \"boolean\"}\n",
    "FIGDIR = \"figures/svg_originals\"  #@param {type: \"string\"}\n",
    "FIGDIR = Path(FIGDIR)\n",
    "\n",
    "HVC_COLOR = \"#e6438c\"  #@param {type: \"string\"}\n",
    "CTRL_COLOR = \"#777777\"  #@param {type: \"string\"}\n",
    "NCM_COLOR = \"#19b382\"  #@param {type: \"string\"}\n",
    "NEUTRAL_COLOR = \"#1968c2\"  #@param {type: \"string\"}\n",
    "HVC_LINESTYLE = \"--\"  #@param {type: \"string\"}\n",
    "CTRL_LINESTYLE = (0, (3, 1, 1, 1)) #@param {type: \"raw\"}\n",
    "NCM_LINESTYLE = \"-\"  #@param {type: \"string\"}\n",
    "AX_COLOR = \"#666666\"  #@param {type: \"string\"}\n",
    "AXIS_SIZE = 14  #@param {type: \"integer\"}\n",
    "LABEL_SIZE = 16  #@param {type: \"integer\"}\n",
    "\n",
    "K_MAX_INITIAL = 3 #@param {type: \"integer\"}\n",
    "\n",
    "FIGDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# JNeurosci column sizes in cm\n",
    "COL1 = 8.5  #@param {type: \"number\"}\n",
    "COL1_5 = 11.6  #@param {type: \"number\"}\n",
    "COL2 = 17.6  #@param {type: \"number\"}\n",
    "\n",
    "COLORMAP = {\n",
    "    \"NCM\": NCM_COLOR,\n",
    "    \"HVC\": HVC_COLOR,\n",
    "    \"CTRL\": CTRL_COLOR\n",
    "}\n",
    "LINEMAP = {\n",
    "    \"NCM\": NCM_LINESTYLE,\n",
    "    \"HVC\": HVC_LINESTYLE,\n",
    "    \"CTRL\": CTRL_LINESTYLE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sdjUTrzQqYJi"
   },
   "outputs": [],
   "source": [
    "mpl.rcParams[\"grid.color\"] = AX_COLOR\n",
    "mpl.rcParams[\"axes.edgecolor\"] = AX_COLOR\n",
    "mpl.rcParams[\"xtick.labelcolor\"] = AX_COLOR\n",
    "mpl.rcParams[\"ytick.labelcolor\"] = AX_COLOR\n",
    "mpl.rcParams[\"xtick.color\"] = AX_COLOR\n",
    "mpl.rcParams[\"ytick.color\"] = AX_COLOR\n",
    "mpl.rcParams[\"ytick.color\"] = AX_COLOR\n",
    "\n",
    "mpl.rcParams[\"axes.titlecolor\"] = AX_COLOR\n",
    "mpl.rcParams[\"axes.labelcolor\"] = AX_COLOR\n",
    "mpl.rcParams[\"figure.edgecolor\"] = AX_COLOR\n",
    "mpl.rcParams[\"grid.color\"] = AX_COLOR\n",
    "mpl.rcParams[\"legend.labelcolor\"] = AX_COLOR\n",
    "mpl.rcParams[\"legend.edgecolor\"] = AX_COLOR\n",
    "mpl.rcParams[\"text.color\"] = AX_COLOR\n",
    "\n",
    "def savedir(rel_path):\n",
    "    \"\"\"Return the save path relative to FIGDIR\"\"\"\n",
    "    return str(FIGDIR / rel_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_Tsvk(df: pd.DataFrame, k_max: int = None) -> Tsvk:\n",
    "    \"\"\"Create a Tsvk instance from a dataframe, or return a cached one for that data\n",
    "    \n",
    "    If the df.index and k_max match a previously computed Tsvk, return that one. Otherwise,\n",
    "    instantiate a new Tsvk() instance.\n",
    "    \n",
    "    Tsvk instances are hashed by a tuple of the dataframe index and k_max requested.\n",
    "    \"\"\"\n",
    "    key = (tuple(df.index), k_max)\n",
    "    if key not in get_or_create_Tsvk.cache:\n",
    "        get_or_create_Tsvk.cache[key] = Tsvk(df, k_max=k_max)\n",
    "    return get_or_create_Tsvk.cache[key]\n",
    "get_or_create_Tsvk.cache = {}\n",
    "\n",
    "\n",
    "def test_get_or_create_Tsvk(df: pd.DataFrame):\n",
    "    backup = get_or_create_Tsvk.cache.copy()\n",
    "    get_or_create_Tsvk.cache = {}\n",
    "    t1 = get_or_create_Tsvk(df[(df.LesionStage == \"prelesion\") & (df.VocalizerSet == \"S1\")], k_max=11)\n",
    "    t2 = get_or_create_Tsvk(df[(df.LesionStage == \"prelesion\") & (df.VocalizerSet == \"S1\")], k_max=11)\n",
    "    t3 = get_or_create_Tsvk(df[(df.LesionStage == \"prelesion\") & (df.VocalizerSet == \"S1\")], k_max=12)\n",
    "    t4 = get_or_create_Tsvk(df[(df.LesionStage == \"postlesion\") & (df.VocalizerSet == \"S2\")], k_max=12)\n",
    "    \n",
    "    assert t1 is t2\n",
    "    assert t1 is not t3\n",
    "    assert t2 is not t3\n",
    "    assert t1 is not t4\n",
    "    assert t2 is not t4\n",
    "    print(\"Tests pass\")\n",
    "    \n",
    "    get_or_create_Tsvk.cache = backup\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shaded_line(x, y, err, line_kwargs: dict = None, fill_kwargs: dict = None, ax: plt.Axes = None):\n",
    "    \"\"\"Plot a line with a shaded error bounds.\n",
    "    \n",
    "    Defaults to alpha=0.2 for shading\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    fill_kwargs = fill_kwargs or {}\n",
    "    line_kwargs = line_kwargs or {}\n",
    "    \n",
    "    # line_kwargs.setdefault(\"linewidth\", 1)\n",
    "    fill_kwargs.setdefault(\"alpha\", 0.2)\n",
    "    fill_kwargs.setdefault(\"zorder\", -1)\n",
    "    fill_kwargs.setdefault(\"facecolor\", line_kwargs.get(\"color\"))\n",
    "\n",
    "    ax.fill_between(x, y - err, y + err, **fill_kwargs)\n",
    "    ax.plot(x, y, **line_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_probability_axes_markers(ax: plt.Axes):\n",
    "    \"\"\"Draws the axes elements common to all learning curves showing P_re and P_nore\"\"\"\n",
    "    ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8])\n",
    "    ax.set_ylim(0, 0.8)\n",
    "    ax.set_yticklabels([0, 0.2, 0.4, 0.6, 0.8], fontsize=6)\n",
    "    border(ax, 1, 0, 0, 1)\n",
    "\n",
    "    \n",
    "def draw_logor_axes_markers(\n",
    "        biggest,\n",
    "        smallest: int = None,\n",
    "        convert_log: bool = True,\n",
    "        ax: plt.Axes = None\n",
    "        ):\n",
    "    \"\"\"Determine and set the yticks of an axis given the data range\n",
    "\n",
    "    Generates a pleasant set of ytick labels and spacing for a given\n",
    "    range of odds ratios.\n",
    "\n",
    "    Typecasts the y values into multiples (e.g. x1, x2, x4, etc) when the\n",
    "    odds ratio is > 1 or as fractions when the odds ratio is less than 1\n",
    "    (e.g. x1/2, x1/4, etc).\n",
    "\n",
    "    It ensures that:\n",
    "    * only powers of 2 are shown\n",
    "    * y=1 is always labeled\n",
    "    * there is a maximum of 5 y-values labeld\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    if smallest is None:\n",
    "        smallest = -biggest\n",
    "\n",
    "    if smallest >= -1:\n",
    "        smallest = -1\n",
    "\n",
    "    if convert_log:\n",
    "        ax.set_yscale(\"log\")\n",
    "\n",
    "    abs_biggest = max(np.abs(smallest), np.abs(biggest))\n",
    "\n",
    "    powers = np.arange(0, abs_biggest + 1)\n",
    "    n = len(powers)\n",
    "    powers = powers[::n // 6 + 1]\n",
    "    vals = np.concatenate([-powers, powers[1:]])\n",
    "    vals = vals[(vals >= smallest) & (vals <= biggest)]\n",
    "\n",
    "    if convert_log:\n",
    "        ticks = np.power(2., vals)\n",
    "    else:\n",
    "        ticks = vals\n",
    "\n",
    "    labels = [r\"x{:d}\".format(int(2 ** v)) if v >= 0 else r\"x1/{:d}\".format(int(2 ** -v)) for v in vals]\n",
    "\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.set_yticklabels(labels, fontsize=6)\n",
    "    \n",
    "    if convert_log:\n",
    "        # Draw a line at unity (1)\n",
    "        ax.hlines(1, *ax.get_xlim(), linestyle=\"--\", color=AX_COLOR, zorder=-1)\n",
    "        ax.set_ylim(np.power(2., smallest), np.power(2., biggest))\n",
    "    else:\n",
    "        ax.hlines(0, *ax.get_xlim(), linestyle=\"--\", color=AX_COLOR, linewidth=0.5, zorder=-1)\n",
    "\n",
    "    border(ax, 1, 0, 0, 1)\n",
    "\n",
    "def draw_k_axis(k_max: int, labels: bool = True, ax: plt.Axes = None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    xticks = np.arange(0, k_max, 5).astype(int)\n",
    "    xticklabels = xticks.copy().astype(str)\n",
    "    xticklabels[1:-1] = \"\"\n",
    "    ax.set_xlim(0, k_max - 1)\n",
    "    ax.set_xticks(xticks)\n",
    "    if labels:\n",
    "        ax.set_xticklabels(xticklabels, fontsize=6)\n",
    "\n",
    "def figure_cm(width: float, height: float, *args, dpi=300, **kwargs) -> plt.Figure:\n",
    "    \"\"\"Make a matplotlib figure in **cm** for a given dpi\n",
    "    \"\"\"\n",
    "    inches_per_cm = 0.393701\n",
    "    fig = plt.figure(*args, dpi=dpi, **kwargs)\n",
    "    print(f\"Figure Dimensions {width:.2f}cm x {height:.2f}cm\")\n",
    "    fig.set_size_inches(width * inches_per_cm, height * inches_per_cm)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZVQPsp4EiB4"
   },
   "source": [
    "## Data modifications\n",
    "\n",
    "Some issues with the data that should be addressed during data analysis and figure plotting are made here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "I8gS4uAjEY-n"
   },
   "outputs": [],
   "source": [
    "POTENTIAL_L = [\"RedHpi0710F\", \"WhiBlu5805F\"]\n",
    "PARTIAL_HVC = [\"RedGra7912M\"]\n",
    "SET_2_CUT_SHORT = \"BluWhi3230M\" # Health issues\n",
    "MICROPHONE_NOT_WORKING_DATE = datetime.date(2020, 11, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJXop8_7HGEw"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Tl0DpetXHGNT"
   },
   "outputs": [],
   "source": [
    "df = load_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests pass\n"
     ]
    }
   ],
   "source": [
    "test_get_or_create_Tsvk(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TMFv2a_G2NS"
   },
   "source": [
    "## Figure 1\n",
    "\n",
    "Figure 1 shows general task information and lesion images, and is not generated by this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEZRJIMrG4Ub"
   },
   "source": [
    "## Figure 2\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucseEpZ8G4Ww"
   },
   "source": [
    "## Figure 3 and 4\n",
    "\n",
    "Figures 3 and 4 plot learning curves before and after lesion (as probabilities and as odds ratios).\n",
    "\n",
    "These figures are generated together here since they were originally one large figure - they have been split into two figures in the latest iteration of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_M918tLPH4_-"
   },
   "outputs": [],
   "source": [
    "def figure3a(ax: plt.Axes = None):\n",
    "    \"\"\"Plots learning curves for inital learning of S1 stimuli before lesion\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Get prelesion data (initial learning)\n",
    "    tsvk = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"prelesion\")\n",
    "        & (df.VocalizerSet == \"S1\")\n",
    "    ], k_max=11)\n",
    "\n",
    "    # Get probability of interruption (avg over subjects) for each k\n",
    "    p_nore = tsvk.nore.p_by_k()\n",
    "    p_re = tsvk.re.p_by_k()\n",
    "\n",
    "    shaded_line(\n",
    "        p_re[\"k\"], \n",
    "        p_re[\"P_int\"], \n",
    "        2 * p_re[\"SE\"],\n",
    "        line_kwargs={\"color\": color_by_reward.get(\"Rewarded\"), \"label\": \"Re\"},\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    shaded_line(\n",
    "        p_nore[\"k\"], \n",
    "        p_nore[\"P_int\"], \n",
    "        2 * p_nore[\"SE\"],\n",
    "        line_kwargs={\"color\": color_by_reward.get(\"Nonrewarded\"), \"label\": \"NoRe\"},\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "def figure3a_odds(ax: plt.Axes = None):\n",
    "    \"\"\"Plots learning curves for inital learning of S1 stimuli before lesion\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Get prelesion data (initial learning)\n",
    "    tsvk = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"prelesion\")\n",
    "        & (df.VocalizerSet == \"S1\")\n",
    "    ], k_max=11)\n",
    "\n",
    "    # Get odds-ratio (avg over subjects) for each k\n",
    "    logOR = tsvk.logOR()\n",
    "\n",
    "    shaded_line(\n",
    "        logOR[\"k\"], \n",
    "        logOR[\"logOR\"], \n",
    "        2 * logOR[\"SE\"],\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    pvalues = logOR[\"pvalue\"]\n",
    "    first_bin = np.where(pvalues < 0.05)[0][0]\n",
    "    \n",
    "    print(\"Figure 3A (Bottom)\")\n",
    "    print(\"------------------\")\n",
    "    print(f\"  Significance by bin: {false_discovery(pvalues, alpha=0.05)}\")\n",
    "    print(f\"  First bin where significant: k={first_bin}\")\n",
    "    \n",
    "    # Draw overlay lines showing the logOR of each individual group\n",
    "    \n",
    "    for treatment in [\"NCM\", \"HVC\", \"CTRL\"]:\n",
    "        tsvk_treatment = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"prelesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "        ], k_max=11)\n",
    "        \n",
    "        logOR = tsvk_treatment.logOR()\n",
    "\n",
    "        ax.plot(\n",
    "            logOR[\"k\"], \n",
    "            logOR[\"logOR\"], \n",
    "            **{\n",
    "                \"linestyle\": LINEMAP[treatment],\n",
    "                \"color\": COLORMAP[treatment],\n",
    "                \"zorder\": -1,\n",
    "                \"linewidth\": 1,\n",
    "            },\n",
    "        )\n",
    "\n",
    "def figure3b(ax: plt.Axes = None):\n",
    "    \"\"\"Plots learning curves for final stage of ladder before lesion\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Get prelesion data (late in learning) \n",
    "    tsvk = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"prelesion\")\n",
    "        & (df.VocalizerSet == \"S1\")\n",
    "        & df.LadderStage.isin([\"SovsSo_8v8_d2\", \"DCvsDC_6v6_d2\"])\n",
    "    ], k_max=11)\n",
    "\n",
    "    # Get probability of interruption as a function of k\n",
    "    p_nore = tsvk.nore.p_by_k()\n",
    "    p_re = tsvk.re.p_by_k()\n",
    "\n",
    "    shaded_line(\n",
    "        p_re[\"k\"], \n",
    "        p_re[\"P_int\"], \n",
    "        2 * p_re[\"SE\"],\n",
    "        line_kwargs={\"color\": color_by_reward.get(\"Rewarded\"), \"label\": \"Re\"},\n",
    "        ax=ax\n",
    "    )\n",
    "    shaded_line(\n",
    "        p_nore[\"k\"], \n",
    "        p_nore[\"P_int\"], \n",
    "        2 * p_nore[\"SE\"],\n",
    "        line_kwargs={\"color\": color_by_reward.get(\"Nonrewarded\"), \"label\": \"NoRe\"},\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    \n",
    "def figure3b_odds(ax: plt.Axes = None):\n",
    "    \"\"\"Plots learning curves for final stage of ladder before lesion\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    # Get prelesion data (late in learning) \n",
    "    tsvk = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"prelesion\")\n",
    "        & (df.VocalizerSet == \"S1\")\n",
    "        & df.LadderStage.isin([\"SovsSo_8v8_d2\", \"DCvsDC_6v6_d2\"])\n",
    "    ], k_max=11)\n",
    "\n",
    "    # Get odds-ratio (avg over subjects) for each k\n",
    "    logOR = tsvk.logOR()\n",
    "\n",
    "    shaded_line(\n",
    "        logOR[\"k\"], \n",
    "        logOR[\"logOR\"], \n",
    "        2 * logOR[\"SE\"],\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    pvalues = logOR[\"pvalue\"]\n",
    "    first_bin = np.where(pvalues < 0.05)[0][0]\n",
    "    \n",
    "    print(\"Figure 3B (Bottom)\")\n",
    "    print(\"------------------\")\n",
    "    print(f\"  Significance by bin: {false_discovery(pvalues, alpha=0.05)}\")\n",
    "    print(f\"  First bin where significant: k={first_bin}\")\n",
    "\n",
    "    # Draw overlay lines showing the logOR of each individual group\n",
    "\n",
    "    for treatment in [\"NCM\", \"HVC\", \"CTRL\"]:\n",
    "        tsvk_treatment = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"prelesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "            & df.LadderStage.isin([\"SovsSo_8v8_d2\", \"DCvsDC_6v6_d2\"])\n",
    "        ], k_max=11)\n",
    "\n",
    "        logOR = tsvk_treatment.logOR()\n",
    "\n",
    "        ax.plot(\n",
    "            logOR[\"k\"], \n",
    "            logOR[\"logOR\"], \n",
    "            **{\n",
    "                \"linestyle\": LINEMAP[treatment],\n",
    "                \"color\": COLORMAP[treatment],\n",
    "                \"zorder\": -1,\n",
    "                \"linewidth\": 1,\n",
    "            },\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mfpDiq-_O1Ja"
   },
   "outputs": [],
   "source": [
    "def figure4a(treatment: str, ax: plt.Axes = None):\n",
    "    \"\"\"Plots learning curves for initial stage of ladder AFTER lesion\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Get post-lesion data in initial sessions after lesion\n",
    "    tsvk = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"postlesion\")\n",
    "        & (df.VocalizerSet == \"S1\")\n",
    "        & (df.SubjectTreatment == treatment)\n",
    "    ], k_max=11)\n",
    "\n",
    "    # Compute probability of interruption as a funciton of k\n",
    "    p_nore = tsvk.nore.p_by_k()\n",
    "    p_re = tsvk.re.p_by_k()\n",
    "\n",
    "    shaded_line(\n",
    "        p_re[\"k\"], \n",
    "        p_re[\"P_int\"], \n",
    "        2 * p_re[\"SE\"],\n",
    "        line_kwargs={\"color\": color_by_reward.get(\"Rewarded\"), \"label\": \"Re\"},\n",
    "        ax=ax\n",
    "    )\n",
    "    shaded_line(\n",
    "        p_nore[\"k\"], \n",
    "        p_nore[\"P_int\"], \n",
    "        2 * p_nore[\"SE\"],\n",
    "        line_kwargs={\"color\": color_by_reward.get(\"Nonrewarded\"), \"label\": \"NoRe\"},\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    \n",
    "def figure4b(ax: plt.Axes = None):\n",
    "    \"\"\"Plots odds ratios of lesioned birds during initial stage of ladder AFTER lesion\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    print(\"Figure 4B\")\n",
    "    print(\"---------\")\n",
    "\n",
    "    # Overlay odds ratio curves for each treatment type\n",
    "\n",
    "    for treatment in [\"NCM\", \"HVC\", \"CTRL\"]:\n",
    "        tsvk_treatment = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"postlesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "        ], k_max=11)\n",
    "\n",
    "        logOR = tsvk_treatment.logOR()\n",
    "\n",
    "        shaded_line(\n",
    "            logOR[\"k\"], \n",
    "            logOR[\"logOR\"], \n",
    "            2 * logOR[\"SE\"],\n",
    "            ax=ax,\n",
    "            line_kwargs={\n",
    "                \"color\": COLORMAP[treatment],\n",
    "                \"linestyle\": LINEMAP[treatment],\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        pvalues = logOR[\"pvalue\"]\n",
    "        first_bin = np.where(pvalues < 0.05)[0][0]\n",
    "        \n",
    "        print(f\" {treatment}\")\n",
    "        print(\"--------\")\n",
    "        print(f\"  Significance by bin: {false_discovery(pvalues, alpha=0.05)}\")\n",
    "        print(f\"  First bin where significant: k={first_bin}\")        \n",
    "        print(f\"  t-test in bin k=0; {treatment}: t({logOR['dof'][0]})={logOR['tstat'][0]:.5f}, p={pvalues[0]:.5f}\")\n",
    "        print(f\"  t-test in bin k=1; {treatment}: t({logOR['dof'][1]})={logOR['tstat'][1]:.5f}, p={pvalues[1]:.5f}\")\n",
    "\n",
    "\n",
    "def figure4c_data(ax: plt.Axes = None):\n",
    "    \"\"\"Generates dictionary of \"delta\", the change in logOR before to after lesion for S1, for each treatment\n",
    "    \n",
    "    We split also generate a table including pre/post lesion and call type in case we want to model call type's\n",
    "    effect. For the figure, we show the group data.\n",
    "    \"\"\"\n",
    "    delta = {}\n",
    "    # call_type_delta_rows = []\n",
    "    \n",
    "    k_array = tuple(np.arange(K_MAX_INITIAL + 1))  # The values of k to compute over\n",
    "\n",
    "#     # First, we generate the dataset with pre/post lesion and call type broken out into their own rows\n",
    "#     for treatment in [\"NCM\", \"HVC\", \"CTRL\"]:\n",
    "#         tsvk_song_pre = get_or_create_Tsvk(df[\n",
    "#             (df.LesionStage == \"prelesion\")\n",
    "#             & (df.VocalizerSet == \"S1\")\n",
    "#             & (df.SubjectTreatment == treatment)\n",
    "#             & (df.StimulusCallType == \"SO\")\n",
    "#             & df.LadderStage.isin([\"SovsSo_8v8_d2\", \"DCvsDC_6v6_d2\"])\n",
    "#         ], k_max=11)\n",
    "#         tsvk_song_post = get_or_create_Tsvk(df[\n",
    "#             (df.LesionStage == \"postlesion\")\n",
    "#             & (df.VocalizerSet == \"S1\")\n",
    "#             & (df.SubjectTreatment == treatment)\n",
    "#             & (df.StimulusCallType == \"SO\")\n",
    "#         ], k_max=11)\n",
    "\n",
    "#         tsvk_dc_pre = get_or_create_Tsvk(df[\n",
    "#             (df.LesionStage == \"prelesion\")\n",
    "#             & (df.VocalizerSet == \"S1\")\n",
    "#             & (df.SubjectTreatment == treatment)\n",
    "#             & (df.StimulusCallType == \"DC\")\n",
    "#             & df.LadderStage.isin([\"SovsSo_8v8_d2\", \"DCvsDC_6v6_d2\"])\n",
    "#         ], k_max=11)\n",
    "#         tsvk_dc_post = get_or_create_Tsvk(df[\n",
    "#             (df.LesionStage == \"postlesion\")\n",
    "#             & (df.VocalizerSet == \"S1\")\n",
    "#             & (df.SubjectTreatment == treatment)\n",
    "#             & (df.StimulusCallType == \"DC\")\n",
    "#         ], k_max=11)\n",
    "        \n",
    "        \n",
    "#         def make_row(row, call_type):\n",
    "#             return {\n",
    "#                 \"CallType\": call_type,\n",
    "#                 \"Treatment\": treatment,\n",
    "#                 \"Delta\": row[\"logOR\"], \n",
    "#                 \"Subject\": row[\"Subject\"]\n",
    "#             }\n",
    "        \n",
    "#         tsvk_song = tsvk_song_pre.logOR_by_subjects(k=k_array).set_index(\"Subject\").join(\n",
    "#             tsvk_song_post.logOR_by_subjects(k=k_array),\n",
    "#             on=\"Subject\",\n",
    "#             rsuffix=\"-post\"\n",
    "#         )\n",
    "#         tsvk_song[\"Delta\"] = tsvk_song.apply(lambda row: row[\"logOR-post\"] - row[\"logOR\"], axis=1)\n",
    "\n",
    "#         tsvk_dc = tsvk_dc_pre.logOR_by_subjects(k=k_array).set_index(\"Subject\").join(\n",
    "#             tsvk_dc_post.logOR_by_subjects(k=k_array),\n",
    "#             on=\"Subject\",\n",
    "#             rsuffix=\"-post\"\n",
    "#         )\n",
    "#         tsvk_dc[\"Delta\"] = tsvk_dc.apply(lambda row: row[\"logOR-post\"] - row[\"logOR\"], axis=1)\n",
    "\n",
    "#         call_type_delta_rows.extend(np.concatenate([\n",
    "#             tsvk_song[\"Delta\"].apply(lambda row: make_row(row, \"Song\"), axis=1),\n",
    "#             tsvk_dc[\"Delta\"].apply(lambda row: make_row(row, \"Song\"), axis=1),\n",
    "#         ]))\n",
    "\n",
    "    # Second, we generate data combining both call types (as in the other learning curve figures)\n",
    "    for treatment in [\"NCM\", \"HVC\", \"CTRL\"]:\n",
    "        tsvk_pre = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"prelesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "            & df.LadderStage.isin([\"SovsSo_8v8_d2\", \"DCvsDC_6v6_d2\"])\n",
    "        ], k_max=11)\n",
    "        tsvk_post = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"postlesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "        ], k_max=11)\n",
    "\n",
    "        delta[treatment] = np.array(\n",
    "            tsvk_post.logOR_by_subjects(k=k_array)[\"logOR\"]\n",
    "            - tsvk_pre.logOR_by_subjects(k=k_array)[\"logOR\"]\n",
    "        )\n",
    "\n",
    "    return delta #, pd.DataFrame(call_type_delta_rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "id": "zinSZEVbVzD6",
    "outputId": "1fba602d-c8b4-4145-d052-e980cd6a99af",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure Dimensions 17.60cm x 6.00cm\n",
      "Figure 3A (Bottom)\n",
      "------------------\n",
      "  Significance by bin: [False False False False  True  True  True  True  True  True  True  True]\n",
      "  First bin where significant: k=4\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "fig = figure_cm(COL2, 6, dpi=300)\n",
    "hspace = 0.4\n",
    "wspace = 0.2\n",
    "gridspec_kw = {\"hspace\": hspace, \"wspace\": wspace}\n",
    "\n",
    "subfigs = fig.subfigures(1, 2, width_ratios=[2, 3])\n",
    "\n",
    "##########\n",
    "# 3A, 3B #\n",
    "##########\n",
    "axes = subfigs[0].subplots(2, 2, sharex=True, gridspec_kw=gridspec_kw)\n",
    "\n",
    "figure3a(axes[0, 0])\n",
    "figure3b(axes[0, 1])\n",
    "figure3a_odds(axes[1, 0])\n",
    "figure3b_odds(axes[1, 1])\n",
    "\n",
    "for ax in axes[0]:\n",
    "    draw_probability_axes_markers(ax=ax)\n",
    "for ax in axes[1]:\n",
    "    draw_logor_axes_markers(smallest=-2, biggest=7, convert_log=False, ax=ax)\n",
    "    ax.set_ylim(-2, 7)\n",
    "    border(ax, 1, 0, 0, 0)\n",
    "for ax in axes[0]:\n",
    "    ax.tick_params(labelbottom=False)\n",
    "for ax in axes[:, 1]:\n",
    "    ax.tick_params(labelleft=False)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    draw_k_axis(k_max=11, ax=ax)\n",
    "    \n",
    "axes[0, 0].legend(fontsize=6, loc=\"upper left\", frameon=False)\n",
    "\n",
    "axes[0, 0].set_ylabel(r\"$P_{\\mathrm{int}}$\", fontsize=8)\n",
    "axes[1, 0].set_ylabel(r\"$OR$\", fontsize=8)\n",
    "\n",
    "subfigs[0].supxlabel(\"Number of Informative Trials Seen\", fontsize=8)\n",
    "subfigs[0].subplots_adjust(bottom=0.15)\n",
    "\n",
    "# 3C: Lesioned subject performances\n",
    "subfigs_right = subfigs[1].subfigures(1, 1)\n",
    "\n",
    "# I'm creating a dummy row so that the top row of plots are aligned with the 3A,3B\n",
    "axes, delete_axes = subfigs_right.subplots(2, 3, sharey=True, gridspec_kw=gridspec_kw)\n",
    "for ax in delete_axes:\n",
    "    ax.remove()\n",
    "\n",
    "######\n",
    "# 4A #\n",
    "######\n",
    "figure4a(\"NCM\", ax=axes[0])\n",
    "figure4a(\"HVC\", ax=axes[1])\n",
    "figure4a(\"CTRL\", ax=axes[2])\n",
    "\n",
    "for ax in axes:\n",
    "    draw_probability_axes_markers(ax=ax)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    draw_k_axis(k_max=11, ax=ax)\n",
    "\n",
    "axes[0].set_ylabel(r\"$P_{\\mathrm{int}}$\", fontsize=8)\n",
    "\n",
    "\n",
    "# 4B: Lesioned subject odds ratios\n",
    "subfigs_bottom = subfigs[1].subfigures(1, 1)\n",
    "delete_axes, axes = subfigs_bottom.subplots(2, 2, gridspec_kw=dict(width_ratios=[1, 2], **gridspec_kw))\n",
    "for ax in delete_axes:\n",
    "    ax.remove()\n",
    "\n",
    "# Split the remaining space \n",
    "last_ax_position = axes[1].get_position()\n",
    "bounds = last_ax_position.bounds\n",
    "w = bounds[2]\n",
    "scatter_ax_bounds = [\n",
    "    bounds[0] + 1.5 * w/6, \n",
    "    bounds[1], \n",
    "    2 * w / 6, \n",
    "    bounds[3]\n",
    "]\n",
    "last_ax_position.x0 = (last_ax_position.x0 + 3.5 * w / 6)\n",
    "axes[1].set_position(last_ax_position)\n",
    "ax_scatter = subfigs_bottom.add_axes(scatter_ax_bounds)\n",
    "\n",
    "# axes[1].sharey(ax_scatter)\n",
    "\n",
    "######\n",
    "# 4B #\n",
    "######\n",
    "figure4b(ax=axes[0])\n",
    "\n",
    "draw_logor_axes_markers(smallest=-2, biggest=7, convert_log=False, ax=axes[0])\n",
    "axes[0].set_ylim(-2, 7)\n",
    "draw_k_axis(k_max=11, ax=axes[0])\n",
    "axes[0].set_ylabel(r\"$OR^{\\dagger}$\", fontsize=8)\n",
    "border(axes[0], 1, 0, 0, 0)\n",
    "\n",
    "\n",
    "######\n",
    "# 4C #\n",
    "######\n",
    "delta = figure4c_data()\n",
    "\n",
    "ax = axes[1]\n",
    "smoothhist(delta[\"CTRL\"], range=(-6.5, 3.5), bins=15, ax=ax, color=CTRL_COLOR, label=\"Controls\", orientation=\"horizontal\", fill=True, alpha=0.3, linewidth=1, linestyle=CTRL_LINESTYLE)\n",
    "smoothhist(delta[\"HVC\"], range=(-6.5, 3.5), bins=15, ax=ax, color=HVC_COLOR, label=\"HVC\", orientation=\"horizontal\", linewidth=1, linestyle=HVC_LINESTYLE)\n",
    "smoothhist(delta[\"NCM\"], range=(-6.5, 3.5), bins=15, ax=ax, color=NCM_COLOR, label=\"NCM\", orientation=\"horizontal\", linewidth=1, linestyle=NCM_LINESTYLE)\n",
    "\n",
    "ax.legend(fontsize=6, loc=\"lower right\", frameon=False)\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ax.set_xlim(xlim[0], xlim[0] + 1.5 * (xlim[1] - xlim[0]))\n",
    "ax.set_xticks([], [])\n",
    "border(ax, 0, 0, 0, 0)\n",
    "ax.tick_params(labelleft=False, labelbottom=False)\n",
    "ax.hlines(0, *plt.xlim(), color=AX_COLOR, linestyle=\"--\", linewidth=0.5, zorder=-1)\n",
    "\n",
    "# draw_logor_axes_markers(smallest=-2, biggest=7, convert_log=False, ax=ax)\n",
    "# ax.set_ylim(-2, 2)\n",
    "\n",
    "ax_scatter.scatter(np.random.normal(0, 0.1, len(delta[\"NCM\"])), delta[\"NCM\"], s=4, linewidth=1, edgecolor=NCM_COLOR, facecolor=\"none\")\n",
    "ax_scatter.scatter(np.random.normal(2, 0.1, len(delta[\"HVC\"])), delta[\"HVC\"], s=4, linewidth=1, edgecolor=HVC_COLOR, facecolor=\"none\")\n",
    "ax_scatter.scatter(np.random.normal(4, 0.1, len(delta[\"CTRL\"])), delta[\"CTRL\"], s=4, linewidth=1, edgecolor=CTRL_COLOR, facecolor=\"none\")\n",
    "\n",
    "ax_scatter.errorbar(\n",
    "    1,\n",
    "    np.mean(delta[\"NCM\"]), \n",
    "    yerr=2 * np.std(delta[\"NCM\"]) / np.sqrt(len(delta)),\n",
    "    markersize=2,\n",
    "    marker=\"D\",\n",
    "    color=NCM_COLOR,\n",
    ")\n",
    "ax_scatter.errorbar(\n",
    "    3,\n",
    "    np.mean(delta[\"HVC\"]), \n",
    "    yerr=2 * np.std(delta[\"HVC\"]) / np.sqrt(len(delta)),\n",
    "    markersize=2,\n",
    "    marker=\"D\",\n",
    "    color=HVC_COLOR,\n",
    ")\n",
    "ax_scatter.errorbar(\n",
    "    5,\n",
    "    np.mean(delta[\"CTRL\"]), \n",
    "    yerr=2 * np.std(delta[\"CTRL\"]) / np.sqrt(len(delta)),\n",
    "    markersize=2,\n",
    "    marker=\"D\",\n",
    "    color=CTRL_COLOR,\n",
    ")\n",
    "\n",
    "ax_scatter.set_xlim(-1, 6)\n",
    "ax_scatter.hlines(0, *plt.xlim(), color=AX_COLOR, linestyle=\"--\", linewidth=0.5, zorder=-1)\n",
    "border(ax_scatter, 1, 0, 0, 0)\n",
    "ax_scatter.set_xticks([])\n",
    "ax_scatter.set_ylabel(r\"$\\frac{OR^{\\dagger}}{OR}$\", fontsize=8, rotation=0)\n",
    "\n",
    "for ax_ in [ax, ax_scatter]:\n",
    "    ax_.set_ylim(-6.5, 3.5)\n",
    "    ax_.set_yticks([-6, -3, 0, 3], [\"x1/64\", \"x1/8\", \"x1\", \"x8\"], fontsize=6)\n",
    "\n",
    "\n",
    "if SAVE_FIGS:\n",
    "    fig.savefig(savedir(\"fig3.svg\"), format=\"svg\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4B Stats\n",
    "\n",
    "In Figure 4B, we test if lesion (\"treatment\") has an effect on logOR during this early period ($k={0, .., 10}$). To test if treatment is a significant factor, we compare nested linear mixed effects models that include/exclude treatment as a fixed effect.\n",
    "\n",
    "We then compare the base model (without treatment) to the alternate model (with treatment) using the likelihood ratio test, defined in `zf_data.stats.likelihood_ratio_test`.\n",
    "\n",
    "The linear mixed effects models here use $k$ as a fixed effect (to account for the general effect of increasing numbers of informative trials), and account for variability in individual subjects as a random effect. In R notation, the base model is\n",
    "\n",
    "$\\mathrm{logOR}^{\\dagger} \\sim k + 1|\\mathrm{Subject}$\n",
    "\n",
    "and the alternate model includes treatment\n",
    "\n",
    "$\\mathrm{logOR}^{\\dagger} \\sim k + \\mathrm{Treatment} + 1|\\mathrm{Subject}$\n",
    "\n",
    "Here, Treatment is a categorical variable that can take the value \"NCM\", \"HVC\", or \"Control\".\n",
    "\n",
    "If we find that Treatment is significant (p < 0.05 for the likelihood ratio test), then we can do a post-hoc analysis, using the same model comparison but limiting the comparisons to NCM vs HVC, HVC vs Control, and NCM vs Control; the magnitude, direction, and significance of pairwise differences can be quantified with a Wald test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_treatments(treatments=(\"NCM\", \"HVC\", \"CTRL\")):\n",
    "    \"\"\"Loads the postlesion data in immediate sessions after lesion for one of the treatment groups\"\"\"\n",
    "    logors = []\n",
    "    for treatment in treatments:\n",
    "        tsvk = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"postlesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "        ], k_max=11)\n",
    "\n",
    "        for i in range(tsvk.k_max):\n",
    "            logOR = tsvk.logOR_by_subjects(k=i)\n",
    "            logOR[\"Treatment\"] = treatment\n",
    "            logOR[\"k\"] = i\n",
    "            logors.append(logOR)\n",
    "\n",
    "    learning_curve_logors = pd.concat(logors)\n",
    "    return learning_curve_logors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve_logors = load_treatments([\"NCM\", \"HVC\", \"CTRL\"])\n",
    "\n",
    "base_model = smf.mixedlm(\n",
    "    \"logOR ~ k\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "alt_model = smf.mixedlm(\n",
    "    \"logOR ~ Treatment + k\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "print(\"Fitted base Model (Just informative trials)\")\n",
    "print(\"-------------------------------------------\")\n",
    "display(base_model.summary())\n",
    "\n",
    "print(\"Fitted alternate model (Including Lesion Treatment)\")\n",
    "print(\"---------------------------------------------------\")\n",
    "display(alt_model.summary())\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(base_model, alt_model)\n",
    "\n",
    "print(\"Figure 4B Stats\")\n",
    "print(\"---------------\")\n",
    "if pvalue < 0.05:\n",
    "    print(\"The hypothesis that the two models are equally likely is rejected\")\n",
    "    print(\"The mixed effects model with Lesion Treatment as a parameter better explains the data\")\n",
    "else:\n",
    "    print(\"The hypothesis that the two models are equally likely is not rejected\")\n",
    "\n",
    "print(f\"Chi2({dof}) = {x:.3f}, p={pvalue:.5f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4B post-hoc tests\n",
    "\n",
    "Thus, lesion has a significant impact on the task performance during the early (k<=10) trials. We next do pairwise tests by including only two treatment conditions and apply the likelihood ratio test, comparing it to the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comparison in [(\"NCM\", \"HVC\"), (\"NCM\", \"CTRL\"), (\"HVC\", \"CTRL\")]:\n",
    "    learning_curve_logors = load_treatments(comparison)\n",
    "\n",
    "    base_model = smf.mixedlm(\n",
    "        \"logOR ~ k\",\n",
    "        groups=learning_curve_logors[\"Subject\"],\n",
    "        data=learning_curve_logors,\n",
    "        re_formula=\"1\",\n",
    "    ).fit(reml=False)\n",
    "\n",
    "    alt_model = smf.mixedlm(\n",
    "        \"logOR ~ Treatment + k\",\n",
    "        groups=learning_curve_logors[\"Subject\"],\n",
    "        data=learning_curve_logors,\n",
    "        re_formula=\"1\",\n",
    "    ).fit(reml=False)\n",
    "\n",
    "    pvalue, x, dof = likelihood_ratio_test(base_model, alt_model)\n",
    "\n",
    "    print(f\"{comparison[0]} different from {comparison[1]}?\")\n",
    "    print(f\"Chi2({dof}) = {x:.3f}, p={pvalue:.5f}\")\n",
    "\n",
    "    display(alt_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoIDuIra7ULk"
   },
   "source": [
    "### Figure 4C Stats\n",
    "\n",
    "Here, we mostly just want to compare each group against zero - are they doing worse or better after lesion? Then we want to see if the groups are different from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wT6O0-uxR2y2"
   },
   "outputs": [],
   "source": [
    "# One way ANOVA\n",
    "anova_result = scipy.stats.f_oneway(delta[\"HVC\"], delta[\"CTRL\"], delta[\"NCM\"])\n",
    "\n",
    "# Individual significance tests\n",
    "alpha_mc = 0.05 / 3\n",
    "alpha = 0.05\n",
    "print(\"Individual significance tests\")\n",
    "print(\"-----------------------------\")\n",
    "t_stat, p_val = scipy.stats.ttest_1samp(delta[\"HVC\"], 0.0)\n",
    "p_val = p_val / 2 if t_stat < 0 else (1 - p_val / 2)\n",
    "print(\" HVC\")\n",
    "print(f\"  T({len(delta['HVC']) - 1}) = {t_stat:.5f}; p={p_val:.5f} ({'*' if p_val < alpha else 'n.s.'})\")\n",
    "\n",
    "t_stat, p_val = scipy.stats.ttest_1samp(delta[\"NCM\"], 0.0)\n",
    "p_val = p_val / 2 if t_stat < 0 else (1 - p_val / 2)\n",
    "print(\" NCM\")\n",
    "print(f\"  T({len(delta['NCM']) - 1}) = {t_stat:.5f}; p={p_val:.5f} ({'*' if p_val < alpha else 'n.s.'})\")\n",
    "\n",
    "t_stat, p_val = scipy.stats.ttest_1samp(delta[\"CTRL\"], 0.0)\n",
    "p_val = p_val / 2 if t_stat < 0 else (1 - p_val / 2)\n",
    "print(\" Controls\")\n",
    "print(f\"  T({len(delta['CTRL']) - 1}) = {t_stat:.5f}; p={p_val:.5f} ({'*' if p_val < alpha else 'n.s.'})\")\n",
    "\n",
    "print()\n",
    "print(\"ANOVA result\")\n",
    "print(\"------------\")\n",
    "print(\" A significant difference between the groups was detected\")\n",
    "print(f\"  F = {anova_result.statistic:.5f}; p = {anova_result.pvalue:.5f}\")\n",
    "\n",
    "print()\n",
    "print(\"Pairwise significance tests\")\n",
    "print(\"----\")\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "tukey = pairwise_tukeyhsd(\n",
    "    endog=list(delta[\"HVC\"]) + list(delta[\"CTRL\"]) + list(delta[\"NCM\"]),\n",
    "    groups=([\"hvc\"] * len(delta[\"HVC\"])) + ([\"ctrl\"] * len(delta[\"CTRL\"])) + ([\"ncm\"] * (len(delta[\"NCM\"]))),\n",
    "    alpha=0.05)\n",
    "\n",
    "print(tukey)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLsRfCVAAy28"
   },
   "source": [
    "## Figure 4\n",
    "\n",
    "This is included in the Figure 3 production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5qCz9RrAxSH"
   },
   "source": [
    "## Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vedUQXJAwvI"
   },
   "outputs": [],
   "source": [
    "def figure5a(treatment: str, ax: plt.Axes = None):\n",
    "    \"\"\"Plots learning curves for learning a new vocalizer set S2\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Get data from the initial learning of S2\n",
    "    tsvk = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"postlesion\")\n",
    "        & (df.VocalizerSet == \"S2\")\n",
    "        & (df.SubjectTreatment == treatment)\n",
    "    ], k_max=11)\n",
    "    \n",
    "    # Compute probability of interruption as a function of k\n",
    "    p_nore = tsvk.nore.p_by_k()\n",
    "    p_re = tsvk.re.p_by_k()\n",
    "\n",
    "    shaded_line(\n",
    "        p_re[\"k\"], \n",
    "        p_re[\"P_int\"], \n",
    "        2 * p_re[\"SE\"],\n",
    "        line_kwargs={\n",
    "            \"color\": color_by_reward.get(\"Rewarded\"), \n",
    "            \"label\": \"Re\",\n",
    "        },\n",
    "        ax=ax\n",
    "    )\n",
    "    shaded_line(\n",
    "        p_nore[\"k\"], \n",
    "        p_nore[\"P_int\"], \n",
    "        2 * p_nore[\"SE\"],\n",
    "        line_kwargs={\"color\": color_by_reward.get(\"Nonrewarded\"), \"label\": \"NoRe\"},\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "def figure5b(ax: plt.Axes = None):\n",
    "    \"\"\"Plots odds-ratios for learning a new vocalizer set S2\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    for treatment in [\"NCM\", \"HVC\", \"CTRL\"]:\n",
    "        tsvk_treatment = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"postlesion\")\n",
    "            & (df.VocalizerSet == \"S2\")\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "        ], k_max=11)\n",
    "\n",
    "        logOR = tsvk_treatment.logOR()\n",
    "\n",
    "        shaded_line(\n",
    "            logOR[\"k\"], \n",
    "            logOR[\"logOR\"], \n",
    "            2 * logOR[\"SE\"],\n",
    "            ax=ax,\n",
    "            line_kwargs={\n",
    "                \"color\": COLORMAP[treatment],\n",
    "                \"linestyle\": LINEMAP[treatment]\n",
    "            },\n",
    "        )\n",
    "\n",
    "        pvalues = logOR[\"pvalue\"]\n",
    "        first_bin = np.where(pvalues < 0.05)[0][0]\n",
    "        print(\"Figure 5B\")\n",
    "        print(\"------------------\")\n",
    "        print(f\"  Significance by bin: {false_discovery(pvalues, alpha=0.05)}\")\n",
    "        print(f\"  First bin where significant: k={first_bin}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8hjn2KRAwxh"
   },
   "outputs": [],
   "source": [
    "fig = figure_cm(COL1_5 - 1, 6, dpi=300)\n",
    "hspace = 0.4\n",
    "wspace = 0.2\n",
    "gridspec_kw = {\"hspace\": hspace, \"wspace\": wspace}\n",
    "subfigs = [None, fig]\n",
    "\n",
    "# I'm creating a dummy row so that the top row of plots are aligned with the 3A,3B\n",
    "axes, delete_axes = subfigs[1].subplots(2, 3, sharey=True, gridspec_kw=gridspec_kw)\n",
    "for ax in delete_axes:\n",
    "    ax.remove()\n",
    "\n",
    "######\n",
    "# 5A #\n",
    "######\n",
    "figure5a(\"NCM\", ax=axes[0])\n",
    "figure5a(\"HVC\", ax=axes[1])\n",
    "figure5a(\"CTRL\", ax=axes[2])\n",
    "\n",
    "for ax in axes:\n",
    "    draw_probability_axes_markers(ax=ax)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    draw_k_axis(k_max=11, ax=ax)\n",
    "\n",
    "axes[0].set_ylabel(r\"$P_{\\mathrm{int}}$\", fontsize=8)\n",
    "axes[0].legend(fontsize=6, loc=\"upper left\", frameon=False)\n",
    "\n",
    "# 3D: Lesioned subject odds ratios\n",
    "subfigs_bottom = subfigs[1].subfigures(1, 1)\n",
    "delete_axes, axes = subfigs_bottom.subplots(2, 2, gridspec_kw=dict(width_ratios=[1, 2], **gridspec_kw))\n",
    "for ax in delete_axes:\n",
    "    ax.remove()\n",
    "\n",
    "\n",
    "######\n",
    "# 5B #\n",
    "######\n",
    "figure5b(ax=axes[0])\n",
    "\n",
    "draw_logor_axes_markers(smallest=-2, biggest=7, convert_log=False, ax=axes[0])\n",
    "axes[0].set_ylim(-2, 7)\n",
    "draw_k_axis(k_max=11, ax=axes[0])\n",
    "axes[0].set_ylabel(r\"$OR^{\\dagger}$\", fontsize=8)\n",
    "border(axes[0], 1, 0, 0, 0)\n",
    "\n",
    "axes[1].remove()\n",
    "\n",
    "fig.supxlabel(\"Number of Informative Trials Seen\", fontsize=8)\n",
    "\n",
    "if SAVE_FIGS:\n",
    "    fig.savefig(savedir(\"fig5.svg\"), format=\"svg\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5b Stats\n",
    "\n",
    "We will do the same model comparisons as in Figure 4b; mixed linear models with subject as random effect and either just k or k and lesion treatment as the fixed effects. The model comparison will be made using the likelihood-ratio test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_treatments_5b(treatments=(\"NCM\", \"HVC\", \"CTRL\")):\n",
    "    \"\"\"Load the data of learning S2 after lesion for one of the three treatment groups\"\"\"\n",
    "    logors = []\n",
    "    for treatment in treatments:\n",
    "        tsvk = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"postlesion\")\n",
    "            & (df.VocalizerSet == \"S2\")\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "        ], k_max=11)\n",
    "\n",
    "        for i in range(tsvk.k_max):\n",
    "            logOR = tsvk.logOR_by_subjects(k=i)\n",
    "            logOR[\"Treatment\"] = treatment\n",
    "            logOR[\"k\"] = i\n",
    "            logors.append(logOR)\n",
    "\n",
    "    learning_curve_logors = pd.concat(logors)\n",
    "    return learning_curve_logors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve_logors = load_treatments_5b([\"NCM\", \"HVC\", \"CTRL\"])\n",
    "\n",
    "base_model = smf.mixedlm(\n",
    "    \"logOR ~ k\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "alt_model = smf.mixedlm(\n",
    "    \"logOR ~ Treatment + k\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(base_model, alt_model)\n",
    "\n",
    "# This is so that the output is not interleaved with the non-convergence warnings\n",
    "# I do this instead of suppressing the warnings, since it is important to know that the model did not converge.\n",
    "time.sleep(0.1)\n",
    "\n",
    "print(\"Base model (Just informative trials)\")\n",
    "print(\"====================================\")\n",
    "display(base_model.summary())\n",
    "\n",
    "print(\"Alternate model (Including Lesion Treatment)\")\n",
    "print(\"============================================\")\n",
    "display(alt_model.summary())\n",
    "\n",
    "print(\"Likelihood ratio test result\")\n",
    "print(\"============================\")\n",
    "if pvalue < 0.05:\n",
    "    print(\"The hypothesis that the two models are equally likely is rejected\")\n",
    "    print(\"The mixed effects model with Lesion Treatment as a parameter better explains the data\")\n",
    "else:\n",
    "    print(\"The hypothesis that the two models are equally likely is not rejected\")\n",
    "\n",
    "print(f\"Chi2({dof}) = {x:.3f}, p={pvalue:.5f}\")\n",
    "\n",
    "for subj, subjdf in learning_curve_logors.groupby(\"Subject\"):\n",
    "    plt.plot(np.arange(11), subjdf[\"logOR\"], color=COLORMAP[subjdf.iloc[0][\"Treatment\"]])\n",
    "    plt.xlabel(\"k\", fontsize=16)\n",
    "    plt.ylabel(\"logOR\", fontsize=16)\n",
    "plt.title(\"Learning curves for each individual subject\", fontsize=16)\n",
    "border(plt.gca(), 1, 0, 0, 1)\n",
    "plt.show()\n",
    "plt.close(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base model did not converge, but the alternate model did. We can still interpret the log-likelihood of the base model (without convergence) as a lower bound on the likelihood. Thus, the p-value from the likelihood-ratio test is a lower bound. Since it is not significant, we know that our p-value is greater than 0.089, and thus we do not reject the null hypothesis that the logOR is different for different treatments. This matches the visual interpretation of the figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xomhdFpMAwz_"
   },
   "source": [
    "## Figure 6\n",
    "\n",
    "Plotting the overall performance on new (S2) stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tIVIkNZqW-H"
   },
   "outputs": [],
   "source": [
    "def figure_6(call_type: str, treatment: str, ax: plt.Axes = None):\n",
    "    \"\"\"Plot the overall odds ratios when the stimuli are well learned\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    colormap = {\n",
    "        \"NCM\": NCM_COLOR,\n",
    "        \"HVC\": HVC_COLOR,\n",
    "        \"CTRL\": CTRL_COLOR\n",
    "    }\n",
    "\n",
    "    tsvk_S1_pre = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"prelesion\")\n",
    "        & (df.VocalizerSet == \"S1\")\n",
    "        & (df.SubjectTreatment == treatment)\n",
    "        & (df.StimulusCallType == call_type)\n",
    "        & df.LadderStage.isin([\"DCvsDC_6v6_d2\", \"SovsSo_8v8_d2\"])\n",
    "    ])\n",
    "    tsvk_S1_post = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"postlesion\")\n",
    "        & (df.VocalizerSet == \"S1\")\n",
    "        & (df.SubjectTreatment == treatment)\n",
    "        & (df.StimulusCallType == call_type)\n",
    "        & df.LadderStage.isin([\"DCvsDC_6v6_d2\", \"SovsSo_8v8_d2\"])\n",
    "    ])\n",
    "    tsvk_S2_post = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"postlesion\")\n",
    "        & (df.VocalizerSet == \"S2\")\n",
    "        & (df.SubjectTreatment == treatment)\n",
    "        & (df.StimulusCallType == call_type)\n",
    "        & df.LadderStage.isin([\"DCvsDC_6v6_d2_S2\", \"SovsSo_8v8_d2_S2\"])\n",
    "    ])\n",
    "        \n",
    "    scores_1 = tsvk_S1_pre.fisher_exact_by_subjects(side=\"greater\")\n",
    "    scores_2 = tsvk_S1_post.fisher_exact_by_subjects(side=\"greater\")\n",
    "    scores_3 = tsvk_S2_post.fisher_exact_by_subjects(side=\"greater\")\n",
    "    \n",
    "    mean_1 = np.mean(scores_1[\"logOR\"])\n",
    "    mean_2 = np.mean(scores_2[\"logOR\"])\n",
    "    mean_3 = np.mean(scores_3[\"logOR\"])\n",
    "    \n",
    "    sem_1 = np.std(scores_1[\"logOR\"]) / np.sqrt(len(scores_1))\n",
    "    sem_2 = np.std(scores_2[\"logOR\"]) / np.sqrt(len(scores_2))\n",
    "    sem_3 = np.std(scores_2[\"logOR\"]) / np.sqrt(len(scores_3))\n",
    "\n",
    "    ax.plot([0, 1, 2], np.array([scores_1[\"logOR\"], scores_2[\"logOR\"], scores_3[\"logOR\"]]), alpha=1, linewidth=1, color=\"0.8\")\n",
    "\n",
    "    ax.scatter(0 * np.ones(len(scores_1)), scores_1[\"logOR\"], s=3, linewidth=1, alpha=1, facecolor=\"none\", edgecolor=\"0.8\")\n",
    "    ax.scatter(1 * np.ones(len(scores_2)), scores_2[\"logOR\"], s=3, linewidth=1, alpha=1, facecolor=\"none\", edgecolor=\"0.8\")\n",
    "    ax.scatter(2 * np.ones(len(scores_3)), scores_3[\"logOR\"], s=3, linewidth=1, alpha=1, facecolor=\"none\", edgecolor=\"0.8\")\n",
    "    \n",
    "    dof = len(scores_1) - 1\n",
    "    print(\" Paired t-test results:\")\n",
    "    print(\" S1 vs S1*\")\n",
    "    tstat, pvalue = scipy.stats.ttest_rel(scores_2[\"logOR\"], scores_1[\"logOR\"], alternative=\"less\")\n",
    "    issig = \"***\" if pvalue < 0.001 else \"**\" if pvalue < 0.01 else \"*\" if pvalue < 0.05 else \"n.s.\"\n",
    "    print(f\" P = {pvalue:.4f} ({issig}), T({dof}) = {tstat}\")\n",
    "    print(\" S1 vs S2*\")\n",
    "    tstat, pvalue = scipy.stats.ttest_rel(scores_3[\"logOR\"], scores_1[\"logOR\"], alternative=\"less\")\n",
    "    issig = \"***\" if pvalue < 0.001 else \"**\" if pvalue < 0.01 else \"*\" if pvalue < 0.05 else \"n.s.\"\n",
    "    print(f\" P = {pvalue:.4f} ({issig}), T({dof}) = {tstat}\")\n",
    "    \n",
    "    print()\n",
    "    print(\" Is above zero results:\")\n",
    "    print(\" S1*\")\n",
    "    tstat, pvalue = scipy.stats.ttest_1samp(scores_2[\"logOR\"], 0, alternative=\"greater\")\n",
    "    issig = \"***\" if pvalue < 0.001 else \"**\" if pvalue < 0.01 else \"*\" if pvalue < 0.05 else \"n.s.\"\n",
    "    print(f\" P = {pvalue:.6f} ({issig}), T({dof}) = {tstat}\")\n",
    "    print(\" S2*\")\n",
    "    tstat, pvalue = scipy.stats.ttest_1samp(scores_3[\"logOR\"], 0, alternative=\"greater\")\n",
    "    issig = \"***\" if pvalue < 0.001 else \"**\" if pvalue < 0.01 else \"*\" if pvalue < 0.05 else \"n.s.\"\n",
    "    print(f\" P = {pvalue:.6f} ({issig}), T({dof}) = {tstat}\")\n",
    "\n",
    "    print()\n",
    "    ax.errorbar(\n",
    "        [0.1, 1.1, 2.1], \n",
    "        [mean_1, mean_2, mean_3], \n",
    "        2 * np.array([sem_1, sem_2, sem_3]),\n",
    "        linewidth=1.5, markersize=4, markerfacecolor=\"white\", color=colormap[treatment], marker=\"d\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pyc2DosWqXAi"
   },
   "outputs": [],
   "source": [
    "fig = figure_cm(COL1_5 - 1, 3, dpi=300)\n",
    "axes = fig.subplots(1, 6)\n",
    "\n",
    "print(\"Song NCM\")\n",
    "print(\"--------\")\n",
    "figure_6(\"SO\", \"NCM\", ax=axes[0])\n",
    "\n",
    "print(\"DC NCM\")\n",
    "print(\"--------\")\n",
    "figure_6(\"DC\", \"NCM\", ax=axes[1])\n",
    "\n",
    "print(\"SO HVC\")\n",
    "print(\"--------\")\n",
    "figure_6(\"SO\", \"HVC\", ax=axes[2])\n",
    "\n",
    "print(\"DC HVC\")\n",
    "print(\"--------\")\n",
    "figure_6(\"DC\", \"HVC\", ax=axes[3])\n",
    "\n",
    "print(\"SO CTRL\")\n",
    "print(\"--------\")\n",
    "figure_6(\"SO\", \"CTRL\", ax=axes[4])\n",
    "\n",
    "print(\"DC CTRL\")\n",
    "print(\"--------\")\n",
    "figure_6(\"DC\", \"CTRL\", ax=axes[5])\n",
    "\n",
    "for ax in axes:\n",
    "    border(ax, 1)\n",
    "    ax.set_xlim(-0.5, 2.5)\n",
    "\n",
    "for ax in axes:\n",
    "    draw_logor_axes_markers(smallest=-2, biggest=8, convert_log=False, ax=ax)\n",
    "    ax.set_ylim(-1, 10)\n",
    "    border(ax, 1)\n",
    "    \n",
    "for ax in axes[1::2]:\n",
    "    border(ax)\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "for ax in axes[[2, 4]]:\n",
    "    ax.tick_params(labelleft=False)\n",
    "\n",
    "axes[0].set_ylabel(\"$OR$\", fontsize=8)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticks(\n",
    "        [0, 1, 2],\n",
    "        [\"S1\", \"S1$^\\dagger$\", \"S2$^\\dagger$\"],\n",
    "        rotation=45,\n",
    "        fontsize=6)\n",
    "\n",
    "if SAVE_FIGS:\n",
    "    fig.savefig(savedir(\"fig6.svg\"), format=\"svg\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7\n",
    "\n",
    "Lesion size analysis on memory effect\n",
    "\n",
    "The first part generates the summary figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zf_data.load_data import load_lesion_summary_table, load_subject_lesion_tables\n",
    "from zf_data.stats import linreg\n",
    "import pandas as pd\n",
    "import statsmodels.regression\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_summary_table = load_lesion_summary_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lesion_size(subject):\n",
    "    if np.any(lesion_summary_table.Subject == subject):\n",
    "        return lesion_summary_table[lesion_summary_table.Subject == subject].iloc[0][\"TotalVolume (mm^3)\"]\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_7(call_type: str, ax: plt.Axes = None):\n",
    "    \"\"\"Create a scatter plot between NCM lesion size and change in logOR before and after lesion\n",
    "    \n",
    "    Also fit a best fit line just to the NCM points\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    for treatment in [\"NCM\", \"HVC\", \"CTRL\"]:\n",
    "        tsvk_S1_pre = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"prelesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & (df.StimulusCallType == call_type)\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "            & df.LadderStage.isin([\"DCvsDC_6v6_d2\", \"SovsSo_8v8_d2\"])\n",
    "        ])\n",
    "        tsvk_S1_post = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"postlesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & (df.StimulusCallType == call_type)\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "            & df.LadderStage.isin([\"DCvsDC_6v6_d2\", \"SovsSo_8v8_d2\"])\n",
    "        ])\n",
    "        \n",
    "        scores_1 = tsvk_S1_pre.fisher_exact_by_subjects(side=\"greater\")\n",
    "        scores_2 = tsvk_S1_post.fisher_exact_by_subjects(side=\"greater\")\n",
    "        assert np.all(scores_1[\"Subject\"] == scores_2[\"Subject\"])\n",
    "        delta = scores_2[\"logOR\"] - scores_1[\"logOR\"]\n",
    "        \n",
    "        lesion_sizes = [get_lesion_size(subject) for subject in scores_1[\"Subject\"]]\n",
    "        \n",
    "        ax.scatter(\n",
    "            lesion_sizes,\n",
    "            delta,\n",
    "            s=30,\n",
    "            linewidth=1,\n",
    "            facecolor=\"none\",\n",
    "            label=treatment,\n",
    "            edgecolor=COLORMAP[treatment]\n",
    "        )\n",
    "    \n",
    "        if treatment == \"NCM\":\n",
    "            x_data = lesion_sizes\n",
    "            y_data = delta\n",
    "\n",
    "            x_data = sm.add_constant(x_data)\n",
    "            result = statsmodels.regression.linear_model.OLS(y_data, x_data)\n",
    "            result = result.fit()\n",
    "            print(\"Best fit line to NCM data\")\n",
    "            print(\"-------------------------\")\n",
    "            print(result.summary())\n",
    "            \n",
    "            x = np.linspace(-0.1, 1.1, num=3)\n",
    "            ax.plot(x, result.params[0] + result.params[1] * x, linewidth=1, color=NCM_COLOR, linestyle=\"--\", zorder=-1)\n",
    "\n",
    "            pvalue = result.pvalues[1]\n",
    "            r2_adj = result.rsquared_adj\n",
    "            ax.text(\n",
    "                0.04,\n",
    "                0.02, \n",
    "                \"$R^2_{adj}$\" + f\"={r2_adj:.2f}\\n\" + \"$p=$\" + f\"{pvalue:.2f}\",\n",
    "                fontsize=8, \n",
    "                verticalalignment=\"bottom\",\n",
    "                horizontalalignment=\"left\",\n",
    "                color=NCM_COLOR,\n",
    "                transform=ax.transAxes\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the slopes of the lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure_cm(COL1_5 - 1, 5, dpi=300)\n",
    "\n",
    "axes = fig.subplots(1, 2, sharey=True)#  gridspec_kw={\"hspace\": 1.0})\n",
    "figure_7(\"SO\", ax=axes[0])\n",
    "figure_7(\"DC\", ax=axes[1])\n",
    "\n",
    "axes[0].set_ylabel(r\"$\\frac{OR^{\\dagger}}{OR}$\", fontsize=10, verticalalignment=\"center\", rotation=0)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim(-0.1, 1.1)\n",
    "    border(ax, 1, 0, 0, 1)\n",
    "    draw_logor_axes_markers(smallest=-7, biggest=2, convert_log=False, ax=ax)\n",
    "    ax.set_ylim(-7, 2.4)\n",
    "    ax.set_xticks([0, 0.5, 1.0], [0, 0.5, 1.0], fontsize=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.supxlabel(\"NCM Lesion Volume ($mm^3$)\", fontsize=8)\n",
    "\n",
    "if SAVE_FIGS:\n",
    "    fig.savefig(savedir(\"fig7.svg\"), format=\"svg\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PaperFigures3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
