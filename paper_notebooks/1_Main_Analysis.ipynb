{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCM, HVC Lesion Analysis\n",
    "\n",
    "This notebook is used to compute the statistics and generate figures presented in the paper.\n",
    "\n",
    "Final versions of the figures were post-processed in Adobe Illustrator.\n",
    "\n",
    "When running this notebook with the `SAVE_FIGS` flag set to True, the EPS files of the figures will be saved to `FIGDIR = \"notebooks/figures/svg_originals\"`.\n",
    "\n",
    "The statistics reported in the paper are printed out in the corresponding section, and (when possible) printed in the same format as in used in the paper. Statistics are rounded to 2 decimal places, and p-values are rounded to 4 decimal places (so that we can report 3 decimal places in the paper, or \"< 0.001\") \n",
    "\n",
    "## 1 Reading the data\n",
    "\n",
    "Reading the data is facilitated by the class `zf_data.Tsvk`, which provides some helper methods to compute quantities used in the paper/figures. The name \"Tsvk\" refers to the term $T^{sv}_k$ from the methods used to compute $p(\\mathrm{int}|s,v,k)$ --- that is the probability that subject $s$ interrupts a particular vocalizer $v$, given that it has seen $k$ informative trials of that vocalizer. \n",
    "\n",
    "Note that this data structure is not required for any analyses, since the raw data can be loaded directly from `zebra-finch-memory-lesions/data/behavior/TrialData.csv` and processed however you choose. However, it can be far more convenient to use this structure since it predefines methods used to perform the analyses found in the paper.\n",
    "\n",
    "We also provide a helper functino `zf_data.load_trials()` for loading the TrialData.csv, which returns a pandas DataFrame containing all operant trials for all subjects.\n",
    "\n",
    "```python\n",
    "from zf_data import load_trials\n",
    "df = load_trials()\n",
    "```\n",
    "\n",
    "## 2 Using the Tsvk data structure\n",
    "\n",
    "A `Tsvk` instance is initialized with (1) a pandas DataFrame containing a filtered subset of operant trials, and (2) a value of `k_max`, the largest informative trial bin to include in the analysis.\n",
    "\n",
    "```python\n",
    "from zf_data import Tsvk\n",
    "tsvk = Tsvk(df[(df.LesionStage == \"prelesion\") & (df.VocalizerSet == \"S1\")], k_max=11)\n",
    "```\n",
    "\n",
    "### Methods\n",
    "\n",
    "Here are some of the helper methods `Tsvk` defines\n",
    "\n",
    "* `tsvk.p(subject, vocalizer, k)`\n",
    "    > Averages $p(\\mathrm{int}|s,v,k)$ over vocalizers. Use `Tsvk.re.p(...)` and `Tsvk.nore.p(...)` to restrict it to either Re or NoRe vocalizers respectively.\n",
    "\n",
    "* `tsvk.re.p_by_k()`, `Tsvk.nore.p_by_k()`\n",
    "    > for each $k$, estimates $p(\\mathrm{int}|Re,k)$ and $p(\\mathrm{int}|NoRe,k)$ by jackknifing over subjects. These are used to produce the group average learning curves in Figure 3A and 3B.\n",
    "\n",
    "* `tsvk.re.odds_by_subjects(k)`, `Tsvk.nore.odds_by_subjects(k)`\n",
    "    > for each $k$, computes odds of interrupting Re or NoRe vocalizers of each subject\n",
    "\n",
    "* `tsvk.logOR_by_subjects(k)`\n",
    "    > for each $k$, compute\n",
    "    $$\n",
    "    \\mathrm{logOR}(s, k)=\\mathrm{log}(Odds(\\mathrm{int}|s,NoRe,k)) - \\mathrm{log}(Odds(\\mathrm{int}|s,Re,k))\n",
    "    $$\n",
    "    for each subject, returning it in a pandas DataFrame\n",
    "\n",
    "* `tsvk.logOR()`\n",
    "    > Computes $\\mathrm{logOR}(k)$ for $k \\in \\{0, .., k_{max}\\}$. At each $k$, the estimate and SEM is estimated using a jackknife procedure over subjects, returning it in a pandas DataFrame. The condition $\\mathrm{logOR}(k) > 0$ is tested with a one-sided paired t-test over subjects. The Benjamini-Hochberg false discovery correction used in the paper should be applied after calling this method.\n",
    "\n",
    "* `tsvk.fisher_exact()`\n",
    "    > Computes the result of a Fisher exact test on the entire DataFrame, with the following contingency matrix. The Fisher exact test returns the estimate of $\\mathrm{OR}=\\frac{ad}{bc}$, 95% confidence bounds on the estimate, and a p-value. \n",
    "\n",
    "|         |Interruptions|Waits|\n",
    "|---------|:-:|:-:|\n",
    "|NoRe     | a | c |\n",
    "|Re       | b | d |\n",
    "\n",
    "### Note on caching results\n",
    "\n",
    "Computing the quantities used in the paper can be relatively slow (10s of seconds). Each `Tsvk` instance caches the result of most of its methods when they are called once, so that re-running a cell happens relatively instantaneously.\n",
    "\n",
    "Sometimes multiple figures/analyses operate on the same subset of data (e.g. the top and bottom figures of Figure 3A and 3B). To avoid re-instantiating a `Tsvk` instance for each analysis (which would cause all the computations to be re-run), a function called `get_or_create_Tsvk` is defined in this notebook which restores a previous `Tsvk` instance if the dataframe and k_max parameter are identical.\n",
    "\n",
    "## 3 Typical analysis pattern\n",
    "\n",
    "\n",
    "The pattern used in this notebook is usually:\n",
    "\n",
    "1. Instantiate a Tsvk object for one or more ranges of data (e.g. S1 & prelesion), e.g.\n",
    "\n",
    "```python\n",
    "tsvk = get_or_create_Tsvk(df[(df.LesionStage == \"prelesion\") & (df.VocalizerSet == \"S1\")], k_max=11)\n",
    "```\n",
    "\n",
    "2. Compute some quantity or quantities of interest, e.g.\n",
    "\n",
    "```python\n",
    "re_probabilities = tsvk.re.p_by_k()\n",
    "nore_probailities = tsvk.nore.p_by_k()\n",
    "```\n",
    "\n",
    "3. Plot or perform statistics on the returned quantities, e.g.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "plt.errorbar(re_probabilities.k, re_probabilities.logOR, y_err=2 * re_probabilities.SE)\n",
    "plt.errorbar(nore_probabilities.k, nore_probabilities.logOR, y_err=2 * nore_probabilities.SE)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qc7rtDVpVIfy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/frederictheunissen/Code/zebra-finch-memory-lesions/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "FtM6Z9DnVaUz"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.regression\n",
    "import statsmodels.formula.api as smf\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.oneway import anova_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\n",
    "\n",
    "from zf_data import Tsvk, load_trials\n",
    "from zf_data.load_data import load_lesion_summary_table\n",
    "from zf_data.plotting import (\n",
    "    border,\n",
    "    color_by_reward,\n",
    "    draw_k_axis,\n",
    "    draw_logor_axes_markers,\n",
    "    draw_probability_axes_markers,\n",
    "    plot_pecking_test_data,\n",
    "    figure_cm,\n",
    "    fig_grid,\n",
    "    smoothhist,\n",
    "    shaded_line,\n",
    ")\n",
    "from zf_data.stats import false_discovery, likelihood_ratio_test, two_to_one_tail\n",
    "from zf_data.utils import parse_p, setup_mpl_params\n",
    "from zf_data.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_mpl_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzrympcKFjGu"
   },
   "source": [
    "## Notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "F4xMWfQUFief"
   },
   "outputs": [],
   "source": [
    "SAVE_FIGS = False  #@param {type: \"boolean\"}\n",
    "FIGDIR = \"figures/svg_originals\"  #@param {type: \"string\"}\n",
    "FIGDIR = Path(FIGDIR)\n",
    "\n",
    "# Create the folder for figure outputs\n",
    "FIGDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def savedir(rel_path):\n",
    "    \"\"\"Return the save path relative to FIGDIR\"\"\"\n",
    "    return str(FIGDIR / rel_path)\n",
    "\n",
    "# JNeurosci column sizes in cm, see https://www.jneurosci.org/content/information-authors\n",
    "COL1 = 8.5  #@param {type: \"number\"}\n",
    "COL1_5 = 11.6  #@param {type: \"number\"}\n",
    "COL2 = 17.6  #@param {type: \"number\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_Tsvk(df: pd.DataFrame, k_max: int = None) -> Tsvk:\n",
    "    \"\"\"Create a Tsvk instance from a dataframe, or return a cached one for that data\n",
    "    \n",
    "    If the df.index and k_max match a previously computed Tsvk, return that one. Otherwise,\n",
    "    instantiate a new Tsvk() instance.\n",
    "    \n",
    "    Tsvk instances are hashed by a tuple of the dataframe index and k_max requested.\n",
    "    \"\"\"\n",
    "    key = (tuple(df.index), k_max)\n",
    "    if key not in get_or_create_Tsvk.cache:\n",
    "        get_or_create_Tsvk.cache[key] = Tsvk(df, k_max=k_max)\n",
    "    return get_or_create_Tsvk.cache[key]\n",
    "get_or_create_Tsvk.cache = {}\n",
    "\n",
    "def test_get_or_create_Tsvk(df: pd.DataFrame):\n",
    "    backup = get_or_create_Tsvk.cache.copy()\n",
    "    get_or_create_Tsvk.cache = {}\n",
    "    t1 = get_or_create_Tsvk(df[(df.LesionStage == \"prelesion\") & (df.VocalizerSet == \"S1\")], k_max=11)\n",
    "    t2 = get_or_create_Tsvk(df[(df.LesionStage == \"prelesion\") & (df.VocalizerSet == \"S1\")], k_max=11)\n",
    "    t3 = get_or_create_Tsvk(df[(df.LesionStage == \"prelesion\") & (df.VocalizerSet == \"S1\")], k_max=12)\n",
    "    t4 = get_or_create_Tsvk(df[(df.LesionStage == \"postlesion\") & (df.VocalizerSet == \"S2\")], k_max=12)\n",
    "    \n",
    "    assert t1 is t2\n",
    "    assert t1 is not t3\n",
    "    assert t2 is not t3\n",
    "    assert t1 is not t4\n",
    "    assert t2 is not t4\n",
    "    print(\"Tests pass\")\n",
    "    \n",
    "    get_or_create_Tsvk.cache = backup\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJXop8_7HGEw"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Tl0DpetXHGNT"
   },
   "outputs": [],
   "source": [
    "df = load_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests pass\n"
     ]
    }
   ],
   "source": [
    "test_get_or_create_Tsvk(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker output problems\n",
    "\n",
    "Sessions on Nov 20, 2020 had technical issues with audio output where speakers in two subjects (BluWhi3230M, HVC) and (GreWhi2703M, HVC), where audio stopped playing audio partway through the session. Four subjects were affected, all in the HVC group, and the sessions were postlesion S1 for 6v6-d2 DCs (BluWhi3230M) and 8v8-d2 Songs (GreWhi2703M). Audio went out at about 12:00. We exclude data on this day after this time.\n",
    "\n",
    "Here I load that extra data and plot it to show what data is excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zf_data.load_data import EXCLUSION_SUBJECTS, EXCLUSION_DATE, EXCLUSION_TIME\n",
    "full_df = load_trials(valid_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in EXCLUSION_SUBJECTS:\n",
    "    subj_df = full_df[(full_df.Date == EXCLUSION_DATE) & (full_df.Subject == subject)]\n",
    "    exclusion_df = full_df[\n",
    "        (full_df.Date == EXCLUSION_DATE)\n",
    "        & (full_df.Time > EXCLUSION_TIME)\n",
    "        & (full_df.Subject == subject)\n",
    "    ]\n",
    "    exclusion_first_index = exclusion_df.Trial.iloc[0]\n",
    "    \n",
    "    fig = plot_pecking_test_data(\n",
    "        subj_df,\n",
    "        [\"StimulusClass\", \"StimulusVocalizerId\", \"StimulusCallType\"],\n",
    "        ticks=True,\n",
    "        figsize=(6, 5),\n",
    "        linekwargs={\"linewidth\": 0.5},\n",
    "        mark_days=True\n",
    "    )\n",
    "    plt.vlines([exclusion_first_index], *plt.ylim(), color=\"Black\", label=\"Speakers stopped playing audio after\")\n",
    "    plt.title(f\"Data for {subject} on 2020-11-20\\nSpeakers were busted partway through session\")\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TMFv2a_G2NS"
   },
   "source": [
    "## Figure 1\n",
    "\n",
    "Figure 1 shows general task information and lesion images, and is not generated by this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEZRJIMrG4Ub"
   },
   "source": [
    "## Figure 2\n",
    "\n",
    "Figure 2 shows trial-by-trial data for two example subjects.\n",
    "\n",
    "We'll show data from before lesion (S1) and after lesion (S1 and S2) for two subjects, named \"XXXOra0037M\" and \"GreWhi2703M\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure2(subject):\n",
    "    subject_df = df[df.Subject == subject]\n",
    "    \n",
    "    fig = plot_pecking_test_data(\n",
    "        subject_df[\n",
    "            (subject_df.VocalizerSet == \"S1\")\n",
    "            & (subject_df.LesionStage == \"prelesion\")\n",
    "        ],\n",
    "        [\"StimulusClass\", \"StimulusVocalizerId\", \"StimulusCallType\"],\n",
    "        ticks=False,\n",
    "        figsize=(6, 3),\n",
    "        linekwargs={\"linewidth\": 0.5},\n",
    "        mark_days=True\n",
    "    )\n",
    "    if SAVE_FIGS:\n",
    "        fig.savefig(savedir(\"fig2B-1.svg\"), format=\"svg\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Postlesion recall\n",
    "    date_df = subject_df[\n",
    "        (subject_df.VocalizerSet == \"S1\")\n",
    "        & (subject_df.LesionStage == \"postlesion\")\n",
    "    ]\n",
    "\n",
    "    fig = plot_pecking_test_data(\n",
    "        date_df,\n",
    "        [\"StimulusClass\", \"StimulusVocalizerId\", \"StimulusCallType\"],\n",
    "        ticks=False,\n",
    "        figsize=(4, 3),\n",
    "        linekwargs={\"linewidth\": 0.5},\n",
    "        mark_days=True\n",
    "    )\n",
    "    if SAVE_FIGS:\n",
    "        fig.savefig(savedir(\"fig2B-2.svg\"), format=\"svg\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Postlesion learning\n",
    "    date_df = subject_df[\n",
    "        (subject_df.VocalizerSet == \"S2\")\n",
    "        & (subject_df.LesionStage == \"postlesion\")\n",
    "    ]\n",
    "\n",
    "    fig = plot_pecking_test_data(\n",
    "        date_df,\n",
    "        [\"StimulusClass\", \"StimulusVocalizerId\", \"StimulusCallType\"],\n",
    "        ticks=False,\n",
    "        figsize=(6, 3),\n",
    "        linekwargs={\"linewidth\": 0.5},\n",
    "        mark_days=True\n",
    "    )\n",
    "    if SAVE_FIGS:\n",
    "        fig.savefig(savedir(\"fig2B-3.svg\"), format=\"svg\", bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncmBirds = ['BlaGre1349M', 'XXXBlu0031M', 'HpiGre0651M', 'GreBla3404M', 'GreBlu5039F', 'WhiBlu5805F',\n",
    "            'RedHpi0710F', 'XXXOra0037F', 'XXXHpi0038M', 'GraWhi4040F']\n",
    "\n",
    "for bird in ncmBirds:\n",
    "    print('-------------------------  ', bird, '  -----------------------')\n",
    "    figure2(bird)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FIGS = True\n",
    "figure2(\"GreBla3404M\")  # Example of Fig1 that also illustrates some relearning\n",
    "SAVE_FIGS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvcBirds = ['BluWhi0398F', 'BluWhi3230M', 'GraYel7337F', 'GreWhi2703M', 'HpiGre8613M', 'BluGre4315M', 'BluRed8773M']\n",
    "\n",
    "for bird in hvcBirds:\n",
    "    print('-------------------------  ', bird, '  -----------------------')\n",
    "    figure2(bird)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FIGS = True\n",
    "figure2(\"HpiGre0651M\")  # Example of HVC lesion with a high performing bird\n",
    "SAVE_FIGS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucseEpZ8G4Ww"
   },
   "source": [
    "## Figure 3 and 4\n",
    "\n",
    "Figures 3 and 4 plot learning curves before and after lesion (as probabilities and as odds ratios).\n",
    "\n",
    "These figures are generated together here since they were originally one large figure - they have been split into two figures in the latest iteration of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_M918tLPH4_-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def figure3a(ax: plt.Axes = None):\n",
    "    \"\"\"Plots learning curves for inital learning of S1 stimuli before lesion\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Get prelesion data (initial learning)\n",
    "    tsvk = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"prelesion\")\n",
    "        & (df.VocalizerSet == \"S1\")\n",
    "    ], k_max=11)\n",
    "\n",
    "    # Get probability of interruption (avg over subjects) for each k\n",
    "    p_nore = tsvk.nore.p_by_k()\n",
    "    p_re = tsvk.re.p_by_k()\n",
    "\n",
    "    shaded_line(\n",
    "        p_re[\"k\"], \n",
    "        p_re[\"P_int\"], \n",
    "        2 * p_re[\"SE\"],\n",
    "        line_kwargs={\"color\": color_by_reward.get(\"Rewarded\"), \"label\": \"Re\"},\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    shaded_line(\n",
    "        p_nore[\"k\"], \n",
    "        p_nore[\"P_int\"], \n",
    "        2 * p_nore[\"SE\"],\n",
    "        line_kwargs={\"color\": color_by_reward.get(\"Nonrewarded\"), \"label\": \"NoRe\"},\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "def figure3a_odds(ax: plt.Axes = None):\n",
    "    \"\"\"Plots learning curves for inital learning of S1 stimuli before lesion\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Get prelesion data (initial learning)\n",
    "    tsvk = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"prelesion\")\n",
    "        & (df.VocalizerSet == \"S1\")\n",
    "    ], k_max=11)\n",
    "\n",
    "    # Get odds-ratio (avg over subjects) for each k\n",
    "    logOR = tsvk.logOR(mode='average-pvalue-vocalizer')\n",
    "\n",
    "    shaded_line(\n",
    "        logOR[\"k\"], \n",
    "        logOR[\"logOR\"], \n",
    "        2 * logOR[\"SE\"],\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    pvalues = logOR[\"pvalue\"]\n",
    "    # first_bin = np.where(false_discovery(pvalues, alpha=0.05))[0][0]\n",
    "    notSig = ~false_discovery(logOR['pvalue'], alpha=0.05)\n",
    "    if len(np.where(notSig)[0]):\n",
    "        first_bin = np.where(notSig)[0][-1]+1\n",
    "    else:\n",
    "        first_bin = 0\n",
    "    \n",
    "    print(\"Figure 3A (Bottom)\")\n",
    "    print(\"------------------\")\n",
    "    print(f\"  During the initial exposures to S1\")\n",
    "    print(f\"  the smallest bin k where log2OR > 0 could be detected from there on: k={first_bin}\")\n",
    "    print(f\"    k=0; logOR = {logOR['logOR'][0]:.2f}, t({logOR['dof'][0]}) = {logOR['tstat'][0]:.2f}, {parse_p(pvalues[0])}\")\n",
    "\n",
    "    # Draw overlay lines showing the logOR of each individual group\n",
    "    \n",
    "    for treatment in [\"NCM\", \"HVC\", \"CTRL\"]:\n",
    "        tsvk_treatment = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"prelesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "        ], k_max=11)\n",
    "        \n",
    "        logOR = tsvk_treatment.logOR()\n",
    "\n",
    "        ax.plot(\n",
    "            logOR[\"k\"], \n",
    "            logOR[\"logOR\"], \n",
    "            **{\n",
    "                \"linestyle\": LINEMAP[treatment],\n",
    "                \"color\": COLORMAP[treatment],\n",
    "                \"zorder\": -1,\n",
    "                \"linewidth\": 1,\n",
    "            },\n",
    "        )\n",
    "\n",
    "def figure3a_odds_fisher(ax: plt.Axes = None):\n",
    "    \"\"\"Plots learning curves for inital learning of S1 stimuli before lesion\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Get prelesion data (initial learning)\n",
    "    tsvk = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"prelesion\")\n",
    "        & (df.VocalizerSet == \"S1\")\n",
    "    ], k_max=11)\n",
    "\n",
    "    # Get odds-ratio (avg over subjects) for each k\n",
    "    logOR = tsvk.logOR(mode='fisher-exact')\n",
    "\n",
    "    shaded_line(\n",
    "        logOR[\"k\"], \n",
    "        logOR[\"logOR\"], \n",
    "        2 * logOR[\"SE\"],\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    pvalues = logOR[\"pvalue\"]\n",
    "    # first_bin = np.where(false_discovery(pvalues, alpha=0.05))[0][0]\n",
    "    notSig = ~false_discovery(logOR['pvalue'], alpha=0.05)\n",
    "    if len(np.where(notSig)[0]):\n",
    "        first_bin = np.where(notSig)[0][-1]+1\n",
    "    else:\n",
    "        first_bin = 0\n",
    "    \n",
    "    print(\"Figure 3A (Bottom)\")\n",
    "    print(\"------------------\")\n",
    "    print(f\"  During the initial exposures to S1\")\n",
    "    print(f\"  the smallest bin k where log2OR > 0 could be detected from there on: k={first_bin}\")\n",
    "    print(f\"    k=0; logOR = {logOR['logOR'][0]:.2f}, {parse_p(pvalues[0])}\")\n",
    "    print(\"Subject pvalues\")\n",
    "    print(logOR['Subject Pvalues'][0])\n",
    "\n",
    "    # Draw overlay lines showing the logOR of each individual group\n",
    "    \n",
    "    for treatment in [\"NCM\", \"HVC\", \"CTRL\"]:\n",
    "        tsvk_treatment = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"prelesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "        ], k_max=11)\n",
    "        \n",
    "        logOR = tsvk_treatment.logOR()\n",
    "\n",
    "        ax.plot(\n",
    "            logOR[\"k\"], \n",
    "            logOR[\"logOR\"], \n",
    "            **{\n",
    "                \"linestyle\": LINEMAP[treatment],\n",
    "                \"color\": COLORMAP[treatment],\n",
    "                \"zorder\": -1,\n",
    "                \"linewidth\": 1,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        \n",
    "def figure3b(ax: plt.Axes = None):\n",
    "    \"\"\"Plots learning curves for final stage of ladder before lesion\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Get prelesion data (late in learning) \n",
    "    tsvk = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"prelesion\")\n",
    "        & (df.VocalizerSet == \"S1\")\n",
    "        & df.LadderStage.isin([\"SovsSo_8v8_d2\", \"DCvsDC_6v6_d2\"])\n",
    "    ], k_max=11)\n",
    "\n",
    "    # Get probability of interruption as a function of k\n",
    "    p_nore = tsvk.nore.p_by_k()\n",
    "    p_re = tsvk.re.p_by_k()\n",
    "\n",
    "    shaded_line(\n",
    "        p_re[\"k\"], \n",
    "        p_re[\"P_int\"], \n",
    "        2 * p_re[\"SE\"],\n",
    "        line_kwargs={\"color\": color_by_reward.get(\"Rewarded\"), \"label\": \"Re\"},\n",
    "        ax=ax\n",
    "    )\n",
    "    shaded_line(\n",
    "        p_nore[\"k\"], \n",
    "        p_nore[\"P_int\"], \n",
    "        2 * p_nore[\"SE\"],\n",
    "        line_kwargs={\"color\": color_by_reward.get(\"Nonrewarded\"), \"label\": \"NoRe\"},\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    \n",
    "def figure3b_odds(ax: plt.Axes = None):\n",
    "    \"\"\"Plots learning curves for final stage of ladder before lesion\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    # Get prelesion data (late in learning) \n",
    "    tsvk = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"prelesion\")\n",
    "        & (df.VocalizerSet == \"S1\")\n",
    "        & df.LadderStage.isin([\"SovsSo_8v8_d2\", \"DCvsDC_6v6_d2\"])\n",
    "    ], k_max=11)\n",
    "\n",
    "    # Get odds-ratio (avg over subjects) for each k\n",
    "    logOR = tsvk.logOR(mode = 'average-pvalue-vocalizer')\n",
    "\n",
    "    shaded_line(\n",
    "        logOR[\"k\"], \n",
    "        logOR[\"logOR\"], \n",
    "        2 * logOR[\"SE\"],\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    pvalues = logOR[\"pvalue\"]\n",
    "    # first_bin = np.where(false_discovery(pvalues, alpha=0.05))[0][0]\n",
    "    notSig = ~false_discovery(logOR['pvalue'], alpha=0.05)\n",
    "    if len(np.where(notSig)[0]):\n",
    "        first_bin = np.where(notSig)[0][-1]+1\n",
    "    else:\n",
    "        first_bin = 0\n",
    "        \n",
    "    \n",
    "    print(\"Figure 3B (Bottom)\")\n",
    "    print(\"------------------\")\n",
    "    print(f\"  On days 6v6-d2/8v8-d2 for pre-lesion learning of S1\")\n",
    "    print(f\"  the smallest bin k where log2OR > 0 could be detected from there on: k={first_bin}\")\n",
    "    print(f\"    k=0; logOR = {logOR['logOR'][0]:.2f}, t({logOR['dof'][0]}) = {logOR['tstat'][0]:.2f}, {parse_p(pvalues[0])}\")\n",
    "\n",
    "    # Draw overlay lines showing the logOR of each individual group\n",
    "\n",
    "    for treatment in [\"NCM\", \"HVC\", \"CTRL\"]:\n",
    "        tsvk_treatment = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"prelesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "            & df.LadderStage.isin([\"SovsSo_8v8_d2\", \"DCvsDC_6v6_d2\"])\n",
    "        ], k_max=11)\n",
    "\n",
    "        logOR = tsvk_treatment.logOR()\n",
    "\n",
    "        ax.plot(\n",
    "            logOR[\"k\"], \n",
    "            logOR[\"logOR\"], \n",
    "            **{\n",
    "                \"linestyle\": LINEMAP[treatment],\n",
    "                \"color\": COLORMAP[treatment],\n",
    "                \"zorder\": -1,\n",
    "                \"linewidth\": 1,\n",
    "            },\n",
    "        )\n",
    "        \n",
    "def figure3b_odds_fisher(ax: plt.Axes = None):\n",
    "    \"\"\"Plots learning curves for final stage of ladder before lesion\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    # Get prelesion data (late in learning) \n",
    "    tsvk = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"prelesion\")\n",
    "        & (df.VocalizerSet == \"S1\")\n",
    "        & df.LadderStage.isin([\"SovsSo_8v8_d2\", \"DCvsDC_6v6_d2\"])\n",
    "    ], k_max=11)\n",
    "\n",
    "    # Get odds-ratio (avg over subjects) for each k\n",
    "    logOR = tsvk.logOR(mode = 'fisher-exact')\n",
    "\n",
    "    shaded_line(\n",
    "        logOR[\"k\"], \n",
    "        logOR[\"logOR\"], \n",
    "        2 * logOR[\"SE\"],\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    pvalues = logOR[\"pvalue\"]\n",
    "    # first_bin = np.where(false_discovery(pvalues, alpha=0.05))[0][0]\n",
    "    notSig = ~false_discovery(logOR['pvalue'], alpha=0.05)\n",
    "    if len(np.where(notSig)[0]):\n",
    "        first_bin = np.where(notSig)[0][-1]+1\n",
    "    else:\n",
    "        first_bin = 0\n",
    "        \n",
    "    \n",
    "    print(\"Figure 3B (Bottom)\")\n",
    "    print(\"------------------\")\n",
    "    print(f\"  On days 6v6-d2/8v8-d2 for pre-lesion learning of S1\")\n",
    "    print(f\"  the smallest bin k where log2OR > 0 could be detected from there on: k={first_bin}\")\n",
    "    print(f\"    k=0; logOR = {logOR['logOR'][0]:.2f}, {parse_p(pvalues[0])}\")\n",
    "    print(\"pvalues per subject:\")\n",
    "    print(logOR['Subject Pvalues'][0])\n",
    "    print(np.sum(logOR['Subject Pvalues'][0]< 0.05), '/', len(logOR['Subject Pvalues'][0]), 'significant')\n",
    "\n",
    "    # Draw overlay lines showing the logOR of each individual group\n",
    "\n",
    "    for treatment in [\"NCM\", \"HVC\", \"CTRL\"]:\n",
    "        tsvk_treatment = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"prelesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "            & df.LadderStage.isin([\"SovsSo_8v8_d2\", \"DCvsDC_6v6_d2\"])\n",
    "        ], k_max=11)\n",
    "\n",
    "        logOR = tsvk_treatment.logOR()\n",
    "\n",
    "        ax.plot(\n",
    "            logOR[\"k\"], \n",
    "            logOR[\"logOR\"], \n",
    "            **{\n",
    "                \"linestyle\": LINEMAP[treatment],\n",
    "                \"color\": COLORMAP[treatment],\n",
    "                \"zorder\": -1,\n",
    "                \"linewidth\": 1,\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfpDiq-_O1Ja",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def figure4a(treatment: str, ax: plt.Axes = None):\n",
    "    \"\"\"Plots learning curves for initial stage of ladder AFTER lesion\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Get post-lesion data in initial sessions after lesion\n",
    "    tsvk = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"postlesion\")\n",
    "        & (df.VocalizerSet == \"S1\")\n",
    "        & (df.SubjectTreatment == treatment)\n",
    "    ], k_max=11)\n",
    "\n",
    "    # Compute probability of interruption as a funciton of k\n",
    "    p_nore = tsvk.nore.p_by_k()\n",
    "    p_re = tsvk.re.p_by_k()\n",
    "\n",
    "    shaded_line(\n",
    "        p_re[\"k\"], \n",
    "        p_re[\"P_int\"], \n",
    "        2 * p_re[\"SE\"],\n",
    "        line_kwargs={\"color\": color_by_reward.get(\"Rewarded\"), \"label\": \"Re\"},\n",
    "        ax=ax\n",
    "    )\n",
    "    shaded_line(\n",
    "        p_nore[\"k\"], \n",
    "        p_nore[\"P_int\"], \n",
    "        2 * p_nore[\"SE\"],\n",
    "        line_kwargs={\"color\": color_by_reward.get(\"Nonrewarded\"), \"label\": \"NoRe\"},\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    \n",
    "def figure4b(ax: plt.Axes = None):\n",
    "    \"\"\"Plots odds ratios of lesioned birds during initial stage of ladder AFTER lesion\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    print(\"Figure 4B\")\n",
    "    print(\"---------\")\n",
    "\n",
    "    # Overlay odds ratio curves for each treatment type\n",
    "\n",
    "    for treatment in [\"NCM\", \"HVC\", \"CTRL\", (\"HVC\", \"CTRL\")]:\n",
    "        if isinstance(treatment, str):\n",
    "            treatment_filter = df.SubjectTreatment == treatment\n",
    "        elif isinstance(treatment, tuple):\n",
    "            treatment_filter = np.zeros_like(df.SubjectTreatment).astype(bool)\n",
    "            for t in treatment:\n",
    "                treatment_filter |= df.SubjectTreatment == t\n",
    "                \n",
    "        tsvk_treatment = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"postlesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & treatment_filter\n",
    "        ], k_max=11)\n",
    "\n",
    "        logOR = tsvk_treatment.logOR(mode='average-pvalue-vocalizer')\n",
    "        \n",
    "        if isinstance(treatment, str):\n",
    "            shaded_line(\n",
    "                logOR[\"k\"], \n",
    "                logOR[\"logOR\"], \n",
    "                2 * logOR[\"SE\"],\n",
    "                ax=ax,\n",
    "                line_kwargs={\n",
    "                    \"color\": COLORMAP[treatment],\n",
    "                    \"linestyle\": LINEMAP[treatment],\n",
    "                },\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Computing combined treatments, {treatment}\")\n",
    "            print(f\"==========================================\")\n",
    "        \n",
    "        pvalues = logOR[\"pvalue\"]\n",
    "        # first_bin = np.where(false_discovery(pvalues, alpha=0.05))[0][0]\n",
    "        notSig = ~false_discovery(logOR['pvalue'], alpha=0.05)\n",
    "        if len(np.where(notSig)[0]):\n",
    "            first_bin = np.where(notSig)[0][-1]+1\n",
    "        else:\n",
    "            first_bin = 0\n",
    "        \n",
    "        print(f\" The {treatment} group after lesion, being re-exposed to S1\")\n",
    "        print(\"--------\")\n",
    "        print(f\"  the smallest bin k where log2OR > 0 could be detected from there on: k={first_bin}\")        \n",
    "\n",
    "        print(f\"    k=0; {treatment}: logOR = {logOR['logOR'][0]:.2f}, t({logOR['dof'][0]}) = {logOR['tstat'][0]:.2f}, {parse_p(pvalues[0])}\")\n",
    "        print(f\"    k=1; {treatment}: logOR = {logOR['logOR'][1]:.2f}, t({logOR['dof'][1]}) = {logOR['tstat'][1]:.2f}, {parse_p(pvalues[1])}\")\n",
    "        print()\n",
    "        \n",
    "        \n",
    "def figure4c_data(ax: plt.Axes = None):\n",
    "    \"\"\"Generates a table of post-lesion logOR\n",
    "    \"\"\"\n",
    "    post_data = []\n",
    "    \n",
    "    # k_array = tuple(np.arange(K_MAX_INITIAL + 1))  # The values of k to compute over\n",
    "\n",
    "    k_array = tuple(np.arange(10 + 1))  # The values of k to compute over\n",
    "    for treatment in [\"NCM\", \"HVC\", \"CTRL\"]:\n",
    "        tsvk_post = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"postlesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "        ], k_max=11)\n",
    "        \n",
    "        logor_data = tsvk_post.logOR_by_subjects(k=k_array)\n",
    "        logor_data[\"Treatment\"] = treatment\n",
    "        \n",
    "        post_data.append(logor_data)\n",
    "\n",
    "\n",
    "    tsvk_post = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"postlesion\")\n",
    "        & (df.VocalizerSet == \"S1\")\n",
    "        & df.SubjectTreatment.isin([\"HVC\", \"CTRL\"])\n",
    "    ], k_max=11)\n",
    "\n",
    "    logor_data = tsvk_post.logOR_by_subjects(k=k_array)\n",
    "    logor_data[\"Treatment\"] = \"HVC+CTRL\"\n",
    "    post_data.append(logor_data)\n",
    "\n",
    "    return pd.concat(post_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "id": "zinSZEVbVzD6",
    "outputId": "1fba602d-c8b4-4145-d052-e980cd6a99af",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = figure_cm(COL2, 6, dpi=300)\n",
    "print()\n",
    "\n",
    "hspace = 0.4\n",
    "wspace = 0.2\n",
    "gridspec_kw = {\"hspace\": hspace, \"wspace\": wspace}\n",
    "\n",
    "subfigs = fig.subfigures(1, 2, width_ratios=[2, 3])\n",
    "\n",
    "##########\n",
    "# 3A, 3B #\n",
    "##########\n",
    "axes = subfigs[0].subplots(2, 2, sharex=True, gridspec_kw=gridspec_kw)\n",
    "\n",
    "figure3a(axes[0, 0])\n",
    "figure3b(axes[0, 1])\n",
    "figure3a_odds_fisher(axes[1, 0])\n",
    "print()\n",
    "figure3b_odds_fisher(axes[1, 1])\n",
    "print()\n",
    "for ax in axes[0]:\n",
    "    draw_probability_axes_markers(ax=ax)\n",
    "for ax in axes[1]:\n",
    "    draw_logor_axes_markers(smallest=-2, biggest=7, convert_log=False, ax=ax)\n",
    "    ax.set_ylim(-2, 7)\n",
    "    border(ax, 1, 0, 0, 0)\n",
    "for ax in axes[0]:\n",
    "    ax.tick_params(labelbottom=False)\n",
    "for ax in axes[:, 1]:\n",
    "    ax.tick_params(labelleft=False)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    draw_k_axis(k_max=11, ax=ax)\n",
    "    \n",
    "axes[0, 0].legend(fontsize=6, loc=\"upper left\", frameon=False)\n",
    "\n",
    "axes[0, 0].set_ylabel(r\"$P_{\\mathrm{int}}$\", fontsize=8)\n",
    "axes[1, 0].set_ylabel(r\"$OR$\", fontsize=8)\n",
    "\n",
    "subfigs[0].supxlabel(\"Number of Informative Trials Seen\", fontsize=8)\n",
    "subfigs[0].subplots_adjust(bottom=0.15)\n",
    "\n",
    "######\n",
    "# 4A #\n",
    "######\n",
    "\n",
    "subfigs_right = subfigs[1].subfigures(1, 1)\n",
    "\n",
    "# I'm creating a dummy row so that the top row of plots are aligned with the 3A,3B\n",
    "axes, delete_axes = subfigs_right.subplots(2, 3, sharey=True, gridspec_kw=gridspec_kw)\n",
    "for ax in delete_axes:\n",
    "    ax.remove()\n",
    "\n",
    "figure4a(\"NCM\", ax=axes[0])\n",
    "figure4a(\"HVC\", ax=axes[1])\n",
    "figure4a(\"CTRL\", ax=axes[2])\n",
    "\n",
    "for ax in axes:\n",
    "    draw_probability_axes_markers(ax=ax)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    draw_k_axis(k_max=11, ax=ax)\n",
    "\n",
    "axes[0].set_ylabel(r\"$P_{\\mathrm{int}}$\", fontsize=8)\n",
    "\n",
    "# 4B: Lesioned subject odds ratios\n",
    "subfigs_bottom = subfigs[1].subfigures(1, 1)\n",
    "delete_axes, axes = subfigs_bottom.subplots(2, 2, gridspec_kw=dict(width_ratios=[1, 2], **gridspec_kw))\n",
    "for ax in delete_axes:\n",
    "    ax.remove()\n",
    "\n",
    "# Split the remaining space \n",
    "last_ax_position = axes[1].get_position()\n",
    "bounds = last_ax_position.bounds\n",
    "w = bounds[2]\n",
    "scatter_ax_bounds = [\n",
    "    bounds[0] + 1.5 * w/6, \n",
    "    bounds[1], \n",
    "    2 * w / 6, \n",
    "    bounds[3]\n",
    "]\n",
    "last_ax_position.x0 = (last_ax_position.x0 + 3.5 * w / 6)\n",
    "axes[1].set_position(last_ax_position)\n",
    "ax_scatter = subfigs_bottom.add_axes(scatter_ax_bounds)\n",
    "\n",
    "# axes[1].sharey(ax_scatter)\n",
    "\n",
    "######\n",
    "# 4B #\n",
    "######\n",
    "figure4b(ax=axes[0])\n",
    "\n",
    "draw_logor_axes_markers(smallest=-2, biggest=7, convert_log=False, ax=axes[0])\n",
    "axes[0].set_ylim(-2, 7)\n",
    "draw_k_axis(k_max=11, ax=axes[0])\n",
    "axes[0].set_ylabel(r\"$OR^{\\dagger}$\", fontsize=8)\n",
    "border(axes[0], 1, 0, 0, 0)\n",
    "\n",
    "\n",
    "######\n",
    "# 4C #\n",
    "######\n",
    "post = figure4c_data()\n",
    "\n",
    "post_ncm = post[post[\"Treatment\"] == \"NCM\"]\n",
    "post_hvc = post[post[\"Treatment\"] == \"HVC\"]\n",
    "post_ctrl = post[post[\"Treatment\"] == \"CTRL\"]\n",
    "post_hvc_and_ctrl = post[post[\"Treatment\"] == \"HVC+CTRL\"]\n",
    "post = post[post[\"Treatment\"] != \"HVC+CTRL\"]\n",
    "\n",
    "ax = axes[1]\n",
    "\n",
    "merged = True\n",
    "if (merged):\n",
    "    smoothhist(np.array(post_hvc_and_ctrl[\"logOR\"]), range=(-2.5, 6.5), bins=20, ax=ax, color=CTRL_COLOR, label=\"HVC+Ctr\", orientation=\"horizontal\", fill=True, alpha=0.3, linewidth=0, linestyle=HVC_LINESTYLE)\n",
    "    smoothhist(np.array(post_hvc_and_ctrl[\"logOR\"]), range=(-2.5, 6.5), bins=20, ax=ax, color=HVC_COLOR, label=\"HVC+Ctr\", orientation=\"horizontal\", linewidth=1, linestyle=HVC_LINESTYLE)\n",
    "    smoothhist(np.array(post_ncm[\"logOR\"]), range=(-2.5, 6.5), bins=20, ax=ax, color=NCM_COLOR, label=\"NCM\", orientation=\"horizontal\", linewidth=1, linestyle=NCM_LINESTYLE)\n",
    "else:\n",
    "    smoothhist(np.array(post_ctrl[\"logOR\"]), range=(-2.5, 6.5), bins=20, ax=ax, color=CTRL_COLOR, label=\"Controls\", orientation=\"horizontal\", fill=True, alpha=0.3, linewidth=1, linestyle=CTRL_LINESTYLE)\n",
    "    smoothhist(np.array(post_hvc[\"logOR\"]), range=(-2.5, 6.5), bins=20, ax=ax, color=HVC_COLOR, label=\"HVC\", orientation=\"horizontal\", linewidth=1, linestyle=HVC_LINESTYLE)\n",
    "    smoothhist(np.array(post_ncm[\"logOR\"]), range=(-2.5, 6.5), bins=20, ax=ax, color=NCM_COLOR, label=\"NCM\", orientation=\"horizontal\", linewidth=1, linestyle=NCM_LINESTYLE)\n",
    "\n",
    "ax.legend(fontsize=6, loc=\"lower right\", frameon=False)\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ax.set_xlim(xlim[0], xlim[0] + 1.5 * (xlim[1] - xlim[0]))\n",
    "ax.set_xticks([], [])\n",
    "border(ax, 0, 0, 0, 0)\n",
    "ax.tick_params(labelleft=False, labelbottom=False)\n",
    "ax.hlines(0, *plt.xlim(), color=AX_COLOR, linestyle=\"--\", linewidth=0.5, zorder=-1)\n",
    "\n",
    "ax_scatter.scatter(np.random.normal(0, 0.1, len(post_ncm)), post_ncm[\"logOR\"], s=4, linewidth=1, edgecolor=NCM_COLOR, facecolor=\"none\")\n",
    "ax_scatter.scatter(np.random.normal(2, 0.1, len(post_hvc)), post_hvc[\"logOR\"], s=4, linewidth=1, edgecolor=HVC_COLOR, facecolor=\"none\")\n",
    "ax_scatter.scatter(np.random.normal(4, 0.1, len(post_ctrl)), post_ctrl[\"logOR\"], s=4, linewidth=1, edgecolor=CTRL_COLOR, facecolor=\"none\")\n",
    "\n",
    "ax_scatter.errorbar(\n",
    "    1,\n",
    "    np.mean(post_ncm[\"logOR\"]), \n",
    "    yerr=2 * np.std(post_ncm[\"logOR\"]) / np.sqrt(len(post_ncm)),\n",
    "    markersize=2,\n",
    "    marker=\"D\",\n",
    "    color=NCM_COLOR,\n",
    ")\n",
    "ax_scatter.errorbar(\n",
    "    3,\n",
    "    np.mean(post_hvc[\"logOR\"]), \n",
    "    yerr=2 * np.std(post_hvc[\"logOR\"]) / np.sqrt(len(post_hvc)),\n",
    "    markersize=2,\n",
    "    marker=\"D\",\n",
    "    color=HVC_COLOR,\n",
    ")\n",
    "ax_scatter.errorbar(\n",
    "    5,\n",
    "    np.mean(post_ctrl[\"logOR\"]), \n",
    "    yerr=2 * np.std(post_ctrl[\"logOR\"]) / np.sqrt(len(post_ctrl)),\n",
    "    markersize=2,\n",
    "    marker=\"D\",\n",
    "    color=CTRL_COLOR,\n",
    ")\n",
    "\n",
    "ax_scatter.set_xlim(-1, 6)\n",
    "ax_scatter.hlines(0, *plt.xlim(), color=AX_COLOR, linestyle=\"--\", linewidth=0.5, zorder=-1)\n",
    "border(ax_scatter, 1, 0, 0, 0)\n",
    "ax_scatter.set_xticks([])\n",
    "ax_scatter.set_ylabel(r\"$OR^{\\dagger}_{k \\leq 10}$\", fontsize=8, rotation=0)\n",
    "\n",
    "for ax_ in [ax, ax_scatter]:\n",
    "    ax_.set_ylim(-2.5, 6.5)\n",
    "    ax_.set_yticks([ -2, 0, 2, 4, 6], [\"x1/4\", \"x1\", \"x4\", \"x16\", \"x64\"], fontsize=6)\n",
    "\n",
    "\n",
    "if SAVE_FIGS:\n",
    "    fig.savefig(savedir(\"fig3.svg\"), format=\"svg\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(savedir(\"fig3_new.svg\"), format=\"svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4B Stats\n",
    "\n",
    "In Figure 4B, we test if lesion (\"treatment\") has an effect on logOR during this early period ($k={0, .., 10}$). To test if treatment is a significant factor, we compare nested linear mixed effects models that include/exclude treatment as a fixed effect.\n",
    "\n",
    "We then compare the nested models (without treatment or interaction) to the full model (with treatment and interaction) using the likelihood ratio test, defined in `zf_data.stats.likelihood_ratio_test` or using the built-in function f_test from the linear models in statsmodel which can test specific hypothesis starting from the full model.  The two yield identical results when the models converge.  When the models don't converge, we will pick the F-test from the larger model.\n",
    "\n",
    "The linear mixed effects models here use $k$ as a fixed effect (to account for the general effect of increasing numbers of informative trials), and account for variability in individual subjects as a random effect. In R notation, the nested model is\n",
    "\n",
    "$\\mathrm{logOR}^{\\dagger} \\sim k + 1|\\mathrm{Subject}$\n",
    "\n",
    "and the full model that includes treatment and the interaction\n",
    "\n",
    "$\\mathrm{logOR}^{\\dagger} \\sim k + \\mathrm{Treatment} + \\mathrm{Treatment:k} + 1|\\mathrm{Subject}$\n",
    "\n",
    "Here, Treatment is a categorical variable that can take the value \"NCM\", \"HVC\", or \"Control\".\n",
    "\n",
    "If we find that Treatment is significant (p < 0.05 for the likelihood ratio test or f_test), then we can do a post-hoc analysis, using the same model comparison but limiting the comparisons to NCM vs HVC, HVC vs Control, and NCM vs Control; the magnitude, direction, and significance of pairwise differences can be quantified with a Wald test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_treatments_before_d1(treatments=(\"NCM\", \"HVC\", \"CTRL\")):\n",
    "    \"\"\"Loads the postlesion data in immediate sessions after lesion for one of the treatment groups\"\"\"\n",
    "    logors = []\n",
    "    for treatment in treatments:\n",
    "        \n",
    "        if isinstance(treatment, str):\n",
    "            treatment_filter = df.SubjectTreatment == treatment\n",
    "            treatment_name = treatment\n",
    "\n",
    "        elif isinstance(treatment, tuple):\n",
    "            treatment_filter = np.zeros_like(df.SubjectTreatment).astype(bool)\n",
    "            for i,t in enumerate(treatment):\n",
    "                treatment_filter |= df.SubjectTreatment == t\n",
    "                if i == 0:\n",
    "                    treatment_name = t\n",
    "                else:\n",
    "                    treatment_name += \"+\"+t\n",
    "                \n",
    "        tsvk = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"prelesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & treatment_filter\n",
    "        ], k_max=11)\n",
    "\n",
    "        for i in range(tsvk.k_max):\n",
    "            logOR = tsvk.logOR_by_subjects(k=i)\n",
    "            logOR[\"Treatment\"] = treatment_name\n",
    "            logOR[\"k\"] = i\n",
    "            logors.append(logOR)\n",
    "\n",
    "    learning_curve_logors = pd.concat(logors)\n",
    "    return learning_curve_logors\n",
    "\n",
    "def load_treatments_before_d2(treatments=(\"NCM\", \"HVC\", \"CTRL\")):\n",
    "    \"\"\"Loads the postlesion data in immediate sessions after lesion for one of the treatment groups\"\"\"\n",
    "    logors = []\n",
    "    for treatment in treatments:\n",
    "        \n",
    "        if isinstance(treatment, str):\n",
    "            treatment_filter = df.SubjectTreatment == treatment\n",
    "            treatment_name = treatment\n",
    "\n",
    "        elif isinstance(treatment, tuple):\n",
    "            treatment_filter = np.zeros_like(df.SubjectTreatment).astype(bool)\n",
    "            for i,t in enumerate(treatment):\n",
    "                treatment_filter |= df.SubjectTreatment == t\n",
    "                if i == 0:\n",
    "                    treatment_name = t\n",
    "                else:\n",
    "                    treatment_name += \"+\"+t\n",
    "                \n",
    "        tsvk = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"prelesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & treatment_filter\n",
    "            & (df.LadderStage.isin([\"SovsSo_8v8_d2\", \"DCvsDC_6v6_d2\"]))\n",
    "            ], k_max=11)\n",
    "\n",
    "        for i in range(tsvk.k_max):\n",
    "            logOR = tsvk.logOR_by_subjects(k=i)\n",
    "            logOR[\"Treatment\"] = treatment_name\n",
    "            logOR[\"k\"] = i\n",
    "            logors.append(logOR)\n",
    "\n",
    "    learning_curve_logors = pd.concat(logors)\n",
    "    return learning_curve_logors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_treatments(treatments=(\"NCM\", \"HVC\", \"CTRL\")):\n",
    "    \"\"\"Loads the postlesion data in immediate sessions after lesion for one of the treatment groups\"\"\"\n",
    "    logors = []\n",
    "    for treatment in treatments:\n",
    "        \n",
    "        if isinstance(treatment, str):\n",
    "            treatment_filter = df.SubjectTreatment == treatment\n",
    "            treatment_name = treatment\n",
    "\n",
    "        elif isinstance(treatment, tuple):\n",
    "            treatment_filter = np.zeros_like(df.SubjectTreatment).astype(bool)\n",
    "            for i,t in enumerate(treatment):\n",
    "                treatment_filter |= df.SubjectTreatment == t\n",
    "                if i == 0:\n",
    "                    treatment_name = t\n",
    "                else:\n",
    "                    treatment_name += \"+\"+t\n",
    "                \n",
    "        tsvk = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"postlesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & treatment_filter\n",
    "        ], k_max=11)\n",
    "\n",
    "        for i in range(tsvk.k_max):\n",
    "            logOR = tsvk.logOR_by_subjects(k=i)\n",
    "            logOR[\"Treatment\"] = treatment_name\n",
    "            logOR[\"k\"] = i\n",
    "            logors.append(logOR)\n",
    "\n",
    "    learning_curve_logors = pd.concat(logors)\n",
    "    return learning_curve_logors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logors_to_logcount(learning_curve_logors):\n",
    "    # Make a data frame with rewarded status as a variable.\n",
    "    dict_counts = {'Subject': [],\n",
    "                            'Counts': [],\n",
    "                            'Rewarded': [],\n",
    "                            'Treatment': [],\n",
    "                             'k' : []\n",
    "                        }\n",
    "\n",
    "    for i, row in learning_curve_logors.iterrows():\n",
    "        dict_counts['Subject'].append(row['Subject'])\n",
    "        dict_counts['Counts'].append(row['noreCounts'])\n",
    "        dict_counts['Rewarded'].append(False)\n",
    "        dict_counts['Treatment'].append(row['Treatment'])\n",
    "        dict_counts['k'].append(row['k'])\n",
    "        dict_counts['Subject'].append(row['Subject'])\n",
    "        dict_counts['Counts'].append(row['reCounts'])\n",
    "        dict_counts['Rewarded'].append(True)\n",
    "        dict_counts['Treatment'].append(row['Treatment'])\n",
    "        dict_counts['k'].append(row['k'])\n",
    "    \n",
    "    return pd.DataFrame(dict_counts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 5B Stats Treatment - NCM vs HVC vs CTR\n",
      "---------------------------------------------\n",
      "\n",
      "k vs full\n",
      "---------\n",
      "We are testing if a model of the learning curves that includes a lesion treatment (3 lines) is a better fit than one without (1 line)\n",
      "\n",
      "Result:\n",
      "     f-test: <F test: F=5.1166060144206185, p=0.0005789212011377428, df_denom=225, df_num=4>\n",
      "    LR: Chi2(4) = 16.68, p = 0.002 (**)\n",
      "\n",
      "k vs T+k\n",
      "--------\n",
      "We are testing if a model of the learning curves that includes a lesion treatment (3 parallel lines) is a better fit than one without (1 line)\n",
      "\n",
      "Result:\n",
      "     f-test: <F test: F=7.5422317607542, p=0.000674046058876117, df_denom=227, df_num=2>\n",
      "    LR: Chi2(2) = 11.37, p = 0.003 (**)\n",
      "\n",
      "T vs full\n",
      "--------\n",
      "We are testing if a model of the learning curves that includes informative trials (3 lines with slopes) is a better fit than one without slope (3 horizontal lines)\n",
      "\n",
      "Result:\n",
      "     f-test: <F test: F=22.26375993835195, p=1.1627998576605951e-12, df_denom=225, df_num=3>\n",
      "    LR: Chi2(3) = 57.99, p < 0.001 (***)\n",
      "\n",
      "Null vs T\n",
      "---------\n",
      "We are testing if a model of the learning curves that includes Treatment (3 horizontal lines) is a better fit than one without treatment (1 horizontal line)\n",
      "\n",
      "Result:\n",
      "     f-test: <F test: F=7.5423700820843065, p=0.0006732791331306472, df_denom=228, df_num=2>\n",
      "    LR: Chi2(2) = 11.37, p = 0.003 (**)\n",
      "\n",
      "T+k vs full\n",
      "---------\n",
      "We are testing if a model of the learning curves that includes Treatment and k (3 arbitrary lines) is a better fit than one without 3 parallel lines\n",
      "\n",
      "Result:\n",
      "     f-test: <F test: F=2.690907379226079, p=0.07000214591111671, df_denom=225, df_num=2>\n",
      "    Chi2(2) = 5.31, p = 0.070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_curve_logors = load_treatments([\"NCM\", \"HVC\", \"CTRL\"])\n",
    "\n",
    "# Models of interest\n",
    "k_model = smf.mixedlm(\n",
    "    \"logORp ~ k\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "T_model = smf.mixedlm(\n",
    "    \"logORp ~ Treatment\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "Tandk_model = smf.mixedlm(\n",
    "    \"logORp ~ Treatment + k\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "full_model = smf.mixedlm(\n",
    "    \"logORp ~ Treatment + k + Treatment:k\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "null_model = smf.mixedlm(\n",
    "    \"logORp ~ 1\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "print(\"Figure 5B Stats Treatment - NCM vs HVC vs CTR\")\n",
    "print(\"---------------------------------------------\")\n",
    "print()\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(k_model, full_model)\n",
    "print('k vs full')\n",
    "print(\"---------\")\n",
    "print(\"We are testing if a model of the learning curves that includes a lesion treatment (3 lines) is a better fit than one without (1 line)\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', full_model.f_test('(Treatment[T.NCM]=0), (Treatment[T.NCM]:k=0), (Treatment[T.HVC]=0), (Treatment[T.HVC]:k=0)'))\n",
    "print(f\"    LR: Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(k_model, Tandk_model)\n",
    "print('k vs T+k')\n",
    "print(\"--------\")\n",
    "print(\"We are testing if a model of the learning curves that includes a lesion treatment (3 parallel lines) is a better fit than one without (1 line)\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', Tandk_model.f_test('(Treatment[T.NCM]=0), (Treatment[T.HVC]=0)'))\n",
    "print(f\"    LR: Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(T_model, full_model)\n",
    "print('T vs full')\n",
    "print(\"--------\")\n",
    "print(\"We are testing if a model of the learning curves that includes informative trials (3 lines with slopes) is a better fit than one without slope (3 horizontal lines)\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', full_model.f_test('(k=0), (Treatment[T.NCM]:k=0), (Treatment[T.HVC]:k=0)'))\n",
    "print(f\"    LR: Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(null_model, T_model)\n",
    "print('Null vs T')\n",
    "print('---------')\n",
    "print(\"We are testing if a model of the learning curves that includes Treatment (3 horizontal lines) is a better fit than one without treatment (1 horizontal line)\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', T_model.f_test('(Treatment[T.NCM]=0),(Treatment[T.HVC]=0)'))\n",
    "print(f\"    LR: Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(Tandk_model, full_model)\n",
    "print('T+k vs full')\n",
    "print('---------')\n",
    "print(\"We are testing if a model of the learning curves that includes Treatment and k (3 arbitrary lines) is a better fit than one without 3 parallel lines\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', full_model.f_test('(Treatment[T.NCM]:k=0),(Treatment[T.HVC]:k=0)'))\n",
    "print(f\"    Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 5B Stats Treatment - NCM vs HVC vs CTR\n",
      "---------------------------------------------\n",
      "\n",
      "k vs full\n",
      "---------\n",
      "We are testing if a model of the learning curves that includes a lesion treatment (3 lines) is a better fit than one without (1 line)\n",
      "\n",
      "Result:\n",
      "     f-test: <F test: F=6.960142813519848, p=2.6728350908871712e-05, df_denom=225, df_num=4>\n",
      "    LR: Chi2(4) = 22.69, p < 0.001 (***)\n",
      "\n",
      "k vs T+k\n",
      "--------\n",
      "We are testing if a model of the learning curves that includes a lesion treatment (3 parallel lines) is a better fit than one without (1 line)\n",
      "\n",
      "Result:\n",
      "     f-test: <F test: F=8.912951749218667, p=0.00018776894365182172, df_denom=227, df_num=2>\n",
      "    LR: Chi2(2) = 12.91, p = 0.002 (**)\n",
      "\n",
      "T vs full\n",
      "--------\n",
      "We are testing if a model of the learning curves that includes informative trials (3 lines with slopes) is a better fit than one without slope (3 horizontal lines)\n",
      "\n",
      "Result:\n",
      "     f-test: <F test: F=20.818088693734005, p=6.113017591562283e-12, df_denom=225, df_num=3>\n",
      "    LR: Chi2(3) = 54.68, p < 0.001 (***)\n",
      "\n",
      "Null vs T\n",
      "---------\n",
      "We are testing if a model of the learning curves that includes Treatment (3 horizontal lines) is a better fit than one without treatment (1 horizontal line)\n",
      "\n",
      "Result:\n",
      "     f-test: <F test: F=8.912555409214038, p=0.00018757751839153854, df_denom=228, df_num=2>\n",
      "    LR: Chi2(2) = 12.91, p = 0.002 (**)\n",
      "\n",
      "T+k vs full\n",
      "---------\n",
      "We are testing if a model of the learning curves that includes Treatment and k (3 arbitrary lines) is a better fit than one without 3 parallel lines\n",
      "\n",
      "Result:\n",
      "     f-test: <F test: F=5.007387290438722, p=0.007452931690126985, df_denom=225, df_num=2>\n",
      "    Chi2(2) = 9.78, p = 0.008 (**)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Models of interest\n",
    "k_model = smf.mixedlm(\n",
    "    \"logORc ~ k\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "T_model = smf.mixedlm(\n",
    "    \"logORc ~ Treatment\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "Tandk_model = smf.mixedlm(\n",
    "    \"logORc ~ Treatment + k\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "full_model = smf.mixedlm(\n",
    "    \"logORc ~ Treatment + k + Treatment:k\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "null_model = smf.mixedlm(\n",
    "    \"logORc ~ 1\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "print(\"Figure 5B Stats Treatment - NCM vs HVC vs CTR\")\n",
    "print(\"---------------------------------------------\")\n",
    "print()\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(k_model, full_model)\n",
    "print('k vs full')\n",
    "print(\"---------\")\n",
    "print(\"We are testing if a model of the learning curves that includes a lesion treatment (3 lines) is a better fit than one without (1 line)\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', full_model.f_test('(Treatment[T.NCM]=0), (Treatment[T.NCM]:k=0), (Treatment[T.HVC]=0), (Treatment[T.HVC]:k=0)'))\n",
    "print(f\"    LR: Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(k_model, Tandk_model)\n",
    "print('k vs T+k')\n",
    "print(\"--------\")\n",
    "print(\"We are testing if a model of the learning curves that includes a lesion treatment (3 parallel lines) is a better fit than one without (1 line)\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', Tandk_model.f_test('(Treatment[T.NCM]=0), (Treatment[T.HVC]=0)'))\n",
    "print(f\"    LR: Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(T_model, full_model)\n",
    "print('T vs full')\n",
    "print(\"--------\")\n",
    "print(\"We are testing if a model of the learning curves that includes informative trials (3 lines with slopes) is a better fit than one without slope (3 horizontal lines)\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', full_model.f_test('(k=0), (Treatment[T.NCM]:k=0), (Treatment[T.HVC]:k=0)'))\n",
    "print(f\"    LR: Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(null_model, T_model)\n",
    "print('Null vs T')\n",
    "print('---------')\n",
    "print(\"We are testing if a model of the learning curves that includes Treatment (3 horizontal lines) is a better fit than one without treatment (1 horizontal line)\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', T_model.f_test('(Treatment[T.NCM]=0),(Treatment[T.HVC]=0)'))\n",
    "print(f\"    LR: Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(Tandk_model, full_model)\n",
    "print('T+k vs full')\n",
    "print('---------')\n",
    "print(\"We are testing if a model of the learning curves that includes Treatment and k (3 arbitrary lines) is a better fit than one without 3 parallel lines\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', full_model.f_test('(Treatment[T.NCM]:k=0),(Treatment[T.HVC]:k=0)'))\n",
    "print(f\"    Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve_counts.to_csv('data/behavior/fig5Count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Counts</th>\n",
       "      <th>Rewarded</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GreBlu5039F</td>\n",
       "      <td>(0, 14)</td>\n",
       "      <td>False</td>\n",
       "      <td>NCM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GreBlu5039F</td>\n",
       "      <td>(4, 18)</td>\n",
       "      <td>True</td>\n",
       "      <td>NCM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GreBla3404M</td>\n",
       "      <td>(6, 20)</td>\n",
       "      <td>False</td>\n",
       "      <td>NCM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GreBla3404M</td>\n",
       "      <td>(25, 39)</td>\n",
       "      <td>True</td>\n",
       "      <td>NCM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GraWhi4040F</td>\n",
       "      <td>(5, 19)</td>\n",
       "      <td>False</td>\n",
       "      <td>NCM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>YelPur7906M</td>\n",
       "      <td>(4, 18)</td>\n",
       "      <td>True</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>WhiWhi2526M</td>\n",
       "      <td>(41, 48)</td>\n",
       "      <td>False</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>WhiWhi2526M</td>\n",
       "      <td>(0, 8)</td>\n",
       "      <td>True</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>RedGra7912M</td>\n",
       "      <td>(150, 163)</td>\n",
       "      <td>False</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>RedGra7912M</td>\n",
       "      <td>(0, 14)</td>\n",
       "      <td>True</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subject      Counts  Rewarded Treatment   k\n",
       "0    GreBlu5039F     (0, 14)     False       NCM   0\n",
       "1    GreBlu5039F     (4, 18)      True       NCM   0\n",
       "2    GreBla3404M     (6, 20)     False       NCM   0\n",
       "3    GreBla3404M    (25, 39)      True       NCM   0\n",
       "4    GraWhi4040F     (5, 19)     False       NCM   0\n",
       "..           ...         ...       ...       ...  ..\n",
       "457  YelPur7906M     (4, 18)      True      CTRL  10\n",
       "458  WhiWhi2526M    (41, 48)     False      CTRL  10\n",
       "459  WhiWhi2526M      (0, 8)      True      CTRL  10\n",
       "460  RedGra7912M  (150, 163)     False      CTRL  10\n",
       "461  RedGra7912M     (0, 14)      True      CTRL  10\n",
       "\n",
       "[462 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_curve_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This figure is not part of the paper\n",
    "# Just to visualize the data we are fitting to investigate the non-convergence\n",
    "for subj, subjdf in learning_curve_logors.groupby(\"Subject\"):\n",
    "    plt.plot(np.arange(11), subjdf[\"logOR\"], color=COLORMAP[subjdf.iloc[0][\"Treatment\"]])\n",
    "    plt.xlabel(\"k\", fontsize=16)\n",
    "    plt.ylabel(\"logOR\", fontsize=16)\n",
    "plt.title(\"Learning curves for each individual subject\", fontsize=16)\n",
    "border(plt.gca(), 1, 0, 0, 1)\n",
    "plt.show()\n",
    "plt.close(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve_logors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4B post-hoc tests\n",
    "\n",
    "Thus, lesion has a significant impact on the task performance during the early ($k \\le 10$) trials. We next do pairwise tests by including only two treatment conditions and apply the likelihood ratio test, comparing it to the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comparison in [(\"NCM\", \"HVC\"), (\"NCM\", \"CTRL\"), (\"HVC\", \"CTRL\")]:\n",
    "    learning_curve_logors = load_treatments(comparison)\n",
    "\n",
    "    base_model = smf.mixedlm(\n",
    "        \"logOR ~ k\",\n",
    "        groups=learning_curve_logors[\"Subject\"],\n",
    "        data=learning_curve_logors,\n",
    "        re_formula=\"1\",\n",
    "    ).fit(reml=False)\n",
    "\n",
    "    alt_model = smf.mixedlm(\n",
    "        \"logOR ~ Treatment + k\",\n",
    "        groups=learning_curve_logors[\"Subject\"],\n",
    "        data=learning_curve_logors,\n",
    "        re_formula=\"1\",\n",
    "    ).fit(reml=False)\n",
    "\n",
    "    pvalue, x, dof = likelihood_ratio_test(base_model, alt_model)\n",
    "\n",
    "    print(f\"Testing if intercept of post-lesion S1 learning curves for {comparison[0]} is significantly different from {comparison[1]}?\")\n",
    "    print(f\" likelihood ratio test; Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "    \n",
    "    # Wald test\n",
    "    z = alt_model.tvalues[f\"Treatment[T.{comparison[0]}]\"]\n",
    "    p = alt_model.wald_test_terms(scalar=True).table.loc[\"Treatment\", \"pvalue\"]\n",
    "    print(f\" Wald test ({comparison[1]} - {comparison[0]}); Z = {z:.2f}, {parse_p(p)}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoIDuIra7ULk"
   },
   "source": [
    "### Figure 4C Stats\n",
    "\n",
    "Here, we first just want to compare each group against zero - How well are the groups doing relative to chance?\n",
    "\n",
    "Then we want to see if the groups are different from each other. We do this using an ANOVA (3 way comparison between the groups) as well as a direct comparison between NCM (n=10) and HVC/Controls combined (n=11)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we measure the magnitude of performance after lesion for k <= 10 (this can be 10 or 3 see above)\n",
    "print(\"Magnitude of postlesion performance on S1 in the k <= 10 window\")\n",
    "for treatment, post_data in [(\"NCM\", post_ncm), (\"HVC\", post_hvc), (\"CTRL\", post_ctrl), (\"HVC+CTRL\", post_hvc_and_ctrl)]:\n",
    "    logor = np.mean(post_data[\"logOR\"])\n",
    "    ttest_result = scipy.stats.ttest_1samp(post_data[\"logOR\"], 0)\n",
    "    print(f\" {treatment}: logOR = {logor:.2f}, t({len(post_data) - 1}) = {ttest_result.statistic:.2f}, {parse_p(ttest_result.pvalue)}\")\n",
    "\n",
    "print()\n",
    "print(\"The following two tests look for a difference between the groups\")\n",
    "print(\"1. ANOVA to test for a difference across the three groups\")\n",
    "print(\"2. Sample sizes matched by combining HVC+CTRL (n=11) to NCM (n=10) and doing a normal t-test\")\n",
    "print()\n",
    "\n",
    "# ANOVA and Tukeys post-hoc test for differences in postlesion logOR for k <= 3\n",
    "anova_result = anova_oneway(\n",
    "    post[\"logOR\"],\n",
    "    groups=post[\"Treatment\"],\n",
    "    use_var=\"equal\",\n",
    ")\n",
    "print(\"1. ANOVA result\")\n",
    "print(\"------------\")\n",
    "print(\" A significant difference between the groups was detected\")\n",
    "print(f\"  F({anova_result.df_num}, {anova_result.df_denom}) = {anova_result.statistic:.2f}; {parse_p(anova_result.pvalue)}\")\n",
    "print()\n",
    "tukey = pairwise_tukeyhsd(\n",
    "    endog=post[\"logOR\"],\n",
    "    groups=post[\"Treatment\"],\n",
    "    alpha=0.05)\n",
    "print(tukey)\n",
    "print()\n",
    "\n",
    "# NCM vs HVC+CTRL\n",
    "print(\"2. Direct comparison between the (sample size matched) NCM and combined HVC+CTRL\")\n",
    "print(\"-----------------------------------------------------------------------------------\")\n",
    "ttest_result = scipy.stats.ttest_ind(post_ncm[\"logOR\"], post_hvc_and_ctrl[\"logOR\"])\n",
    "print(f\" {treatment}: t({len(post_ncm) + len(post_hvc_and_ctrl) - 2}) = {ttest_result.statistic:.2f}, {parse_p(ttest_result.pvalue)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLsRfCVAAy28"
   },
   "source": [
    "## Figure 4\n",
    "\n",
    "This is included in the Figure 3 production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5qCz9RrAxSH"
   },
   "source": [
    "## Figure 4 Lower Panels\n",
    "This figure was figure 5 in the first version of the paper.  The functions called figure5 create that lower panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vedUQXJAwvI"
   },
   "outputs": [],
   "source": [
    "def figure5a(treatment: str, ax: plt.Axes = None):\n",
    "    \"\"\"Plots learning curves for learning a new vocalizer set S2\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Get data from the initial learning of S2\n",
    "    tsvk = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"postlesion\")\n",
    "        & (df.VocalizerSet == \"S2\")\n",
    "        & (df.SubjectTreatment == treatment)\n",
    "    ], k_max=11)\n",
    "    \n",
    "    # Compute probability of interruption as a function of k\n",
    "    p_nore = tsvk.nore.p_by_k()\n",
    "    p_re = tsvk.re.p_by_k()\n",
    "\n",
    "    shaded_line(\n",
    "        p_re[\"k\"], \n",
    "        p_re[\"P_int\"], \n",
    "        2 * p_re[\"SE\"],\n",
    "        line_kwargs={\n",
    "            \"color\": color_by_reward.get(\"Rewarded\"), \n",
    "            \"label\": \"Re\",\n",
    "        },\n",
    "        ax=ax\n",
    "    )\n",
    "    shaded_line(\n",
    "        p_nore[\"k\"], \n",
    "        p_nore[\"P_int\"], \n",
    "        2 * p_nore[\"SE\"],\n",
    "        line_kwargs={\"color\": color_by_reward.get(\"Nonrewarded\"), \"label\": \"NoRe\"},\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "def figure5b(ax: plt.Axes = None):\n",
    "    \"\"\"Plots odds-ratios for learning a new vocalizer set S2\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    print(\"Figure 5B\")\n",
    "    print(\"------------------\")\n",
    "\n",
    "    for treatment in [\"NCM\", \"HVC\", \"CTRL\", (\"HVC\", \"CTRL\")]:\n",
    "        if isinstance(treatment, str):\n",
    "            treatment_filter = df.SubjectTreatment == treatment\n",
    "        elif isinstance(treatment, tuple):\n",
    "            treatment_filter = np.zeros_like(df.SubjectTreatment).astype(bool)\n",
    "            for t in treatment:\n",
    "                treatment_filter |= df.SubjectTreatment == t\n",
    "                \n",
    "        tsvk_treatment = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"postlesion\")\n",
    "            & (df.VocalizerSet == \"S2\")\n",
    "            & treatment_filter\n",
    "        ], k_max=11)\n",
    "\n",
    "        logOR = tsvk_treatment.logOR()\n",
    "        \n",
    "        if isinstance(treatment, str):\n",
    "            shaded_line(\n",
    "                logOR[\"k\"], \n",
    "                logOR[\"logOR\"], \n",
    "                2 * logOR[\"SE\"],\n",
    "                ax=ax,\n",
    "                line_kwargs={\n",
    "                    \"color\": COLORMAP[treatment],\n",
    "                    \"linestyle\": LINEMAP[treatment],\n",
    "                },\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Computing combined treatments, {treatment}\")\n",
    "            print(f\"==========================================\")\n",
    "        \n",
    "        pvalues = logOR[\"pvalue\"]\n",
    "        # first_bin = np.where(false_discovery(pvalues, alpha=0.05))[0][0]\n",
    "        notSig = ~false_discovery(logOR['pvalue'], alpha=0.05)\n",
    "        if len(np.where(notSig)[0]):\n",
    "            first_bin = np.where(notSig)[0][-1]+1\n",
    "        else:\n",
    "            first_bin = 0\n",
    "        \n",
    "        print(f\" The {treatment} group after lesion, being exposed to S2\")\n",
    "        print(\"--------\")\n",
    "        print(f\"  the smallest bin k where log2OR > 0 could be detected from there on: k={first_bin}\")        \n",
    "\n",
    "        print(f\"    k=0; {treatment}: logOR = {logOR['logOR'][0]:.2f}, t({logOR['dof'][0]}) = {logOR['tstat'][0]:.2f}, {parse_p(pvalues[0])}\")\n",
    "        print(f\"    k=1; {treatment}: logOR = {logOR['logOR'][1]:.2f}, t({logOR['dof'][1]}) = {logOR['tstat'][1]:.2f}, {parse_p(pvalues[1])}\")\n",
    "        print()\n",
    "\n",
    "def figure5c_data(ax: plt.Axes = None):\n",
    "    \"\"\"Generates a table of post-lesion logOR\n",
    "    \"\"\"\n",
    "    post_data = []\n",
    "    \n",
    "    # k_array = tuple(np.arange(K_MAX_INITIAL + 1))  # The values of k to compute over\n",
    "\n",
    "    k_array = tuple(np.arange(10 + 1))  # The values of k to compute over\n",
    "    for treatment in [\"NCM\", \"HVC\", \"CTRL\"]:\n",
    "        tsvk_post = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"postlesion\")\n",
    "            & (df.VocalizerSet == \"S2\")\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "        ], k_max=11)\n",
    "        \n",
    "        logor_data = tsvk_post.logOR_by_subjects(k=k_array)\n",
    "        logor_data[\"Treatment\"] = treatment\n",
    "        \n",
    "        post_data.append(logor_data)\n",
    "\n",
    "\n",
    "    tsvk_post = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"postlesion\")\n",
    "        & (df.VocalizerSet == \"S2\")\n",
    "        & df.SubjectTreatment.isin([\"HVC\", \"CTRL\"])\n",
    "    ], k_max=11)\n",
    "\n",
    "    logor_data = tsvk_post.logOR_by_subjects(k=k_array)\n",
    "    logor_data[\"Treatment\"] = \"HVC+CTRL\"\n",
    "    post_data.append(logor_data)\n",
    "\n",
    "    return pd.concat(post_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8hjn2KRAwxh",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = figure_cm(COL1_5 - 1, 6, dpi=300)\n",
    "hspace = 0.4\n",
    "wspace = 0.2\n",
    "gridspec_kw = {\"hspace\": hspace, \"wspace\": wspace}\n",
    "subfigs = [None, fig]\n",
    "\n",
    "# I'm creating a dummy row so that the top row of plots are aligned with the 3A,3B\n",
    "axes, delete_axes = subfigs[1].subplots(2, 3, sharey=True, gridspec_kw=gridspec_kw)\n",
    "for ax in delete_axes:\n",
    "    ax.remove()\n",
    "\n",
    "\n",
    "######\n",
    "# 5A #\n",
    "######\n",
    "figure5a(\"NCM\", ax=axes[0])\n",
    "figure5a(\"HVC\", ax=axes[1])\n",
    "figure5a(\"CTRL\", ax=axes[2])\n",
    "\n",
    "for ax in axes:\n",
    "    draw_probability_axes_markers(ax=ax)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    draw_k_axis(k_max=11, ax=ax)\n",
    "\n",
    "axes[0].set_ylabel(r\"$P_{\\mathrm{int}}$\", fontsize=8)\n",
    "axes[0].legend(fontsize=6, loc=\"upper left\", frameon=False)\n",
    "\n",
    "\n",
    "######\n",
    "# 5B #\n",
    "######\n",
    "# Lesioned subjects learning curves with odds ratios\n",
    "subfigs_bottom = subfigs[1].subfigures(1, 1)\n",
    "delete_axes, axes = subfigs_bottom.subplots(2, 2, gridspec_kw=dict(width_ratios=[1, 2], **gridspec_kw))\n",
    "for ax in delete_axes:\n",
    "    ax.remove()\n",
    "\n",
    "figure5b(ax=axes[0])\n",
    "\n",
    "draw_logor_axes_markers(smallest=-2, biggest=7, convert_log=False, ax=axes[0])\n",
    "axes[0].set_ylim(-2, 7)\n",
    "draw_k_axis(k_max=11, ax=axes[0])\n",
    "axes[0].set_ylabel(r\"$OR^{\\dagger}$\", fontsize=8)\n",
    "border(axes[0], 1, 0, 0, 0)\n",
    "\n",
    "\n",
    "fig.supxlabel(\"Number of Informative Trials Seen\", fontsize=8)\n",
    "\n",
    "######\n",
    "# 5C #\n",
    "######\n",
    "# Split the remaining space \n",
    "last_ax_position = axes[1].get_position()\n",
    "bounds = last_ax_position.bounds\n",
    "w = bounds[2]\n",
    "scatter_ax_bounds = [\n",
    "    bounds[0] + 1.5 * w/6, \n",
    "    bounds[1], \n",
    "    2 * w / 6, \n",
    "    bounds[3]\n",
    "]\n",
    "last_ax_position.x0 = (last_ax_position.x0 + 3.5 * w / 6)\n",
    "axes[1].set_position(last_ax_position)\n",
    "ax_scatter = subfigs_bottom.add_axes(scatter_ax_bounds)\n",
    "\n",
    "\n",
    "post = figure5c_data()\n",
    "\n",
    "post_ncm = post[post[\"Treatment\"] == \"NCM\"]\n",
    "post_hvc = post[post[\"Treatment\"] == \"HVC\"]\n",
    "post_ctrl = post[post[\"Treatment\"] == \"CTRL\"]\n",
    "post_hvc_and_ctrl = post[post[\"Treatment\"] == \"HVC+CTRL\"]\n",
    "post = post[post[\"Treatment\"] != \"HVC+CTRL\"]\n",
    "\n",
    "ax = axes[1]\n",
    "\n",
    "merged = True\n",
    "if (merged):\n",
    "    smoothhist(np.array(post_hvc_and_ctrl[\"logOR\"]), range=(-2.5, 6.5), bins=20, ax=ax, color=CTRL_COLOR, label=\"HVC+Ctr\", orientation=\"horizontal\", fill=True, alpha=0.3, linewidth=0, linestyle=HVC_LINESTYLE)\n",
    "    smoothhist(np.array(post_hvc_and_ctrl[\"logOR\"]), range=(-2.5, 6.5), bins=20, ax=ax, color=HVC_COLOR, label=\"HVC+Ctr\", orientation=\"horizontal\", linewidth=1, linestyle=HVC_LINESTYLE)\n",
    "    smoothhist(np.array(post_ncm[\"logOR\"]), range=(-2.5, 6.5), bins=20, ax=ax, color=NCM_COLOR, label=\"NCM\", orientation=\"horizontal\", linewidth=1, linestyle=NCM_LINESTYLE)\n",
    "else:\n",
    "    smoothhist(np.array(post_ctrl[\"logOR\"]), range=(-2.5, 6.5), bins=20, ax=ax, color=CTRL_COLOR, label=\"Controls\", orientation=\"horizontal\", fill=True, alpha=0.3, linewidth=1, linestyle=CTRL_LINESTYLE)\n",
    "    smoothhist(np.array(post_hvc[\"logOR\"]), range=(-2.5, 6.5), bins=20, ax=ax, color=HVC_COLOR, label=\"HVC\", orientation=\"horizontal\", linewidth=1, linestyle=HVC_LINESTYLE)\n",
    "    smoothhist(np.array(post_ncm[\"logOR\"]), range=(-2.5, 6.5), bins=20, ax=ax, color=NCM_COLOR, label=\"NCM\", orientation=\"horizontal\", linewidth=1, linestyle=NCM_LINESTYLE)\n",
    "\n",
    "ax.legend(fontsize=6, loc=\"lower right\", frameon=False)\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ax.set_xlim(xlim[0], xlim[0] + 1.5 * (xlim[1] - xlim[0]))\n",
    "ax.set_xticks([], [])\n",
    "border(ax, 0, 0, 0, 0)\n",
    "ax.tick_params(labelleft=False, labelbottom=False)\n",
    "ax.hlines(0, *plt.xlim(), color=AX_COLOR, linestyle=\"--\", linewidth=0.5, zorder=-1)\n",
    "\n",
    "ax_scatter.scatter(np.random.normal(0, 0.1, len(post_ncm)), post_ncm[\"logOR\"], s=4, linewidth=1, edgecolor=NCM_COLOR, facecolor=\"none\")\n",
    "ax_scatter.scatter(np.random.normal(2, 0.1, len(post_hvc)), post_hvc[\"logOR\"], s=4, linewidth=1, edgecolor=HVC_COLOR, facecolor=\"none\")\n",
    "ax_scatter.scatter(np.random.normal(4, 0.1, len(post_ctrl)), post_ctrl[\"logOR\"], s=4, linewidth=1, edgecolor=CTRL_COLOR, facecolor=\"none\")\n",
    "\n",
    "ax_scatter.errorbar(\n",
    "    1,\n",
    "    np.mean(post_ncm[\"logOR\"]), \n",
    "    yerr=2 * np.std(post_ncm[\"logOR\"]) / np.sqrt(len(post_ncm)),\n",
    "    markersize=2,\n",
    "    marker=\"D\",\n",
    "    color=NCM_COLOR,\n",
    ")\n",
    "ax_scatter.errorbar(\n",
    "    3,\n",
    "    np.mean(post_hvc[\"logOR\"]), \n",
    "    yerr=2 * np.std(post_hvc[\"logOR\"]) / np.sqrt(len(post_hvc)),\n",
    "    markersize=2,\n",
    "    marker=\"D\",\n",
    "    color=HVC_COLOR,\n",
    ")\n",
    "ax_scatter.errorbar(\n",
    "    5,\n",
    "    np.mean(post_ctrl[\"logOR\"]), \n",
    "    yerr=2 * np.std(post_ctrl[\"logOR\"]) / np.sqrt(len(post_ctrl)),\n",
    "    markersize=2,\n",
    "    marker=\"D\",\n",
    "    color=CTRL_COLOR,\n",
    ")\n",
    "\n",
    "ax_scatter.set_xlim(-1, 6)\n",
    "ax_scatter.hlines(0, *plt.xlim(), color=AX_COLOR, linestyle=\"--\", linewidth=0.5, zorder=-1)\n",
    "border(ax_scatter, 1, 0, 0, 0)\n",
    "ax_scatter.set_xticks([])\n",
    "ax_scatter.set_ylabel(r\"$OR^{\\dagger}_{k \\leq 10}$\", fontsize=8, rotation=0)\n",
    "\n",
    "for ax_ in [ax, ax_scatter]:\n",
    "    ax_.set_ylim(-2.5, 6.5)\n",
    "    ax_.set_yticks([ -2, 0, 2, 4, 6], [\"x1/4\", \"x1\", \"x4\", \"x16\", \"x64\"], fontsize=6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if SAVE_FIGS:\n",
    "    fig.savefig(savedir(\"fig5.svg\"), format=\"svg\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(savedir(\"fig5_new.svg\"), format=\"svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5b Stats\n",
    "\n",
    "We will do the same model comparisons as in Figure 4b; mixed linear models with subject as random effect and k and lesion treatment and their interactions as the fixed effects. The model comparison will be made using the likelihood-ratio test and, equivalently, the F-test.  The two yield identical results when the models converge.  When the models don't converge, we will pick the F-test from the larger model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_treatments_5b(treatments=(\"NCM\", \"HVC\", \"CTRL\")):\n",
    "    \"\"\"Loads the postlesion data in immediate sessions after lesion for one of the treatment groups\"\"\"\n",
    "    logors = []\n",
    "    for treatment in treatments:\n",
    "        \n",
    "        if isinstance(treatment, str):\n",
    "            treatment_filter = df.SubjectTreatment == treatment\n",
    "            treatment_name = treatment\n",
    "\n",
    "        elif isinstance(treatment, tuple):\n",
    "            treatment_filter = np.zeros_like(df.SubjectTreatment).astype(bool)\n",
    "            for i,t in enumerate(treatment):\n",
    "                treatment_filter |= df.SubjectTreatment == t\n",
    "                if i == 0:\n",
    "                    treatment_name = t\n",
    "                else:\n",
    "                    treatment_name += '+'+t\n",
    "                \n",
    "        tsvk = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"postlesion\")\n",
    "            & (df.VocalizerSet == \"S2\")\n",
    "            & treatment_filter\n",
    "        ], k_max=11)\n",
    "\n",
    "        for i in range(tsvk.k_max):\n",
    "            logOR = tsvk.logOR_by_subjects(k=i)\n",
    "            logOR[\"Treatment\"] = treatment_name\n",
    "            logOR[\"k\"] = i\n",
    "            logors.append(logOR)\n",
    "\n",
    "    learning_curve_logors = pd.concat(logors)\n",
    "    return learning_curve_logors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve_logors = load_treatments_5b([\"NCM\", \"HVC\", \"CTRL\"])\n",
    "\n",
    "# Models of interest\n",
    "k_model = smf.mixedlm(\n",
    "    \"logOR ~ k\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "T_model = smf.mixedlm(\n",
    "    \"logOR ~ Treatment\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "Tandk_model = smf.mixedlm(\n",
    "    \"logOR ~ Treatment + k\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "full_model = smf.mixedlm(\n",
    "    \"logOR ~ Treatment + k + Treatment:k\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "null_model = smf.mixedlm(\n",
    "    \"logOR ~ 1\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "print(\"Figure 5B Stats Treatment - NCM vs (HVC+CTR) \")\n",
    "print(\"---------------------------------------------\")\n",
    "print()\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(k_model, full_model)\n",
    "print('k vs full')\n",
    "print(\"---------\")\n",
    "print(\"We are testing if a model of the learning curves that includes a lesion treatment (3 lines) is a better fit than one without (1 line)\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', full_model.f_test('(Treatment[T.NCM]=0), (Treatment[T.NCM]:k=0), (Treatment[T.HVC]=0), (Treatment[T.HVC]:k=0)'))\n",
    "print(f\"    LR: Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(k_model, Tandk_model)\n",
    "print('k vs T+k')\n",
    "print(\"--------\")\n",
    "print(\"We are testing if a model of the learning curves that includes a lesion treatment (3 parallel lines) is a better fit than one without (1 line)\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', Tandk_model.f_test('(Treatment[T.NCM]=0), (Treatment[T.HVC]=0)'))\n",
    "print(f\"    LR: Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(T_model, full_model)\n",
    "print('T vs full')\n",
    "print(\"--------\")\n",
    "print(\"We are testing if a model of the learning curves that includes informative trials (3 lines with slopes) is a better fit than one without slope (3 horizontal lines)\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', full_model.f_test('(k=0), (Treatment[T.NCM]:k=0), (Treatment[T.HVC]:k=0)'))\n",
    "print(f\"    LR: Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(null_model, T_model)\n",
    "print('Null vs T')\n",
    "print('---------')\n",
    "print(\"We are testing if a model of the learning curves that includes Treatment (3 horizontal lines) is a better fit than one without treatment (1 horizontal line)\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', T_model.f_test('(Treatment[T.NCM]=0),(Treatment[T.HVC]=0)'))\n",
    "print(f\"    LR: Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(Tandk_model, full_model)\n",
    "print('T+k vs full')\n",
    "print('---------')\n",
    "print(\"We are testing if a model of the learning curves that includes Treatment and k (3 arbitrary lines) is a better fit than one without 3 parallel lines\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', full_model.f_test('(Treatment[T.NCM]:k=0),(Treatment[T.HVC]:k=0)'))\n",
    "print(f\"    Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting lines \n",
    "\n",
    "treatments = [\"NCM\", \"HVC\", \"CTRL\", (\"HVC\",\"CTRL\")]\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "\n",
    "for treatment in treatments:\n",
    "    # S1 Pre Lesion - first learning\n",
    "    learning_curve_logors = load_treatments_before_d1([treatment])\n",
    "    k_model = smf.mixedlm(\n",
    "        \"logOR ~ k\",\n",
    "        groups=learning_curve_logors[\"Subject\"],\n",
    "        data=learning_curve_logors,\n",
    "        re_formula=\"~1\",\n",
    "    ).fit()\n",
    "    if isinstance(treatment, str):\n",
    "        treatment_name = treatment\n",
    "    elif isinstance(treatment, tuple):\n",
    "        for i,t in enumerate(treatment):\n",
    "            if i == 0:\n",
    "                treatment_name = t\n",
    "            else:\n",
    "                treatment_name += '+'+t\n",
    "    label = pd.Series(['S1d1-'+treatment_name, 'S1d1-'+treatment_name], index = ['Intercept', 'k'])\n",
    "    lineDF = pd.concat([label, k_model.fe_params, k_model.bse_fe], axis=1)\n",
    "    lineDF.columns = ['Treat.', 'Coef.', 'SE']\n",
    "    display(lineDF.style.format(precision=2))\n",
    "    \n",
    "    # S1 Pre Lesion - second learning\n",
    "    learning_curve_logors = load_treatments_before_d2([treatment])\n",
    "    k_model = smf.mixedlm(\n",
    "        \"logOR ~ k\",\n",
    "        groups=learning_curve_logors[\"Subject\"],\n",
    "        data=learning_curve_logors,\n",
    "        re_formula=\"~1\",\n",
    "    ).fit()\n",
    "    if isinstance(treatment, str):\n",
    "        treatment_name = treatment\n",
    "    elif isinstance(treatment, tuple):\n",
    "        for i,t in enumerate(treatment):\n",
    "            if i == 0:\n",
    "                treatment_name = t\n",
    "            else:\n",
    "                treatment_name += '+'+t\n",
    "    label = pd.Series(['S1d2-'+treatment_name, 'S1d2-'+treatment_name], index = ['Intercept', 'k'])\n",
    "    lineDF = pd.concat([label, k_model.fe_params, k_model.bse_fe], axis=1)\n",
    "    lineDF.columns = ['Treat.', 'Coef.', 'SE']\n",
    "    display(lineDF.style.format(precision=2))\n",
    "    \n",
    "    # S1 Post Lession\n",
    "    learning_curve_logors = load_treatments([treatment])\n",
    "    k_model = smf.mixedlm(\n",
    "        \"logOR ~ k\",\n",
    "        groups=learning_curve_logors[\"Subject\"],\n",
    "        data=learning_curve_logors,\n",
    "        re_formula=\"~1\",\n",
    "    ).fit()\n",
    "    if isinstance(treatment, str):\n",
    "        treatment_name = treatment\n",
    "    elif isinstance(treatment, tuple):\n",
    "        for i,t in enumerate(treatment):\n",
    "            if i == 0:\n",
    "                treatment_name = t\n",
    "            else:\n",
    "                treatment_name += '+'+t\n",
    "    label = pd.Series(['S1-'+treatment_name, 'S1-'+treatment_name], index = ['Intercept', 'k'])\n",
    "    lineDF = pd.concat([label, k_model.fe_params, k_model.bse_fe], axis=1)\n",
    "    lineDF.columns = ['Treat.', 'Coef.', 'SE']\n",
    "    display(lineDF.style.format(precision=2))\n",
    "\n",
    "    \n",
    "    # S2 Post Lesion\n",
    "    learning_curve_logors = load_treatments_5b([treatment])\n",
    "    k_model = smf.mixedlm(\n",
    "        \"logOR ~ k\",\n",
    "        groups=learning_curve_logors[\"Subject\"],\n",
    "        data=learning_curve_logors,\n",
    "        re_formula=\"~1\",\n",
    "    ).fit()\n",
    "    if isinstance(treatment, str):\n",
    "        treatment_name = treatment\n",
    "    elif isinstance(treatment, tuple):\n",
    "        for i,t in enumerate(treatment):\n",
    "            if i == 0:\n",
    "                treatment_name = t\n",
    "            else:\n",
    "                treatment_name += '+'+t\n",
    "    label = pd.Series(['S2-'+treatment_name, 'S2-'+treatment_name], index = ['Intercept', 'k'])\n",
    "    lineDF = pd.concat([label, k_model.fe_params, k_model.bse_fe], axis=1)\n",
    "    lineDF.columns = ['Treat.', 'Coef.', 'SE']\n",
    "    display(lineDF.style.format(precision=2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learning_curve_logors = load_treatments_5b([\"NCM\", (\"HVC\", \"CTRL\")])\n",
    "\n",
    "# Models of interest\n",
    "k_model = smf.mixedlm(\n",
    "    \"logOR ~ k\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "T_model = smf.mixedlm(\n",
    "    \"logOR ~ Treatment\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "Tandk_model = smf.mixedlm(\n",
    "    \"logOR ~ Treatment + k\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "full_model = smf.mixedlm(\n",
    "    \"logOR ~ Treatment + k + Treatment:k\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "null_model = smf.mixedlm(\n",
    "    \"logOR ~ 1\",\n",
    "    groups=learning_curve_logors[\"Subject\"],\n",
    "    data=learning_curve_logors,\n",
    "    re_formula=\"~1\",\n",
    ").fit(reml=False)\n",
    "\n",
    "print(\"Figure 5B Stats Treatment - NCM vs (HVC+CTR) \")\n",
    "print(\"---------------------------------------------\")\n",
    "print()\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(k_model, full_model)\n",
    "print('k vs full')\n",
    "print(\"---------\")\n",
    "print(\"We are testing if a model of the learning curves that includes a lesion treatment (2 lines) is a better fit than one without (1 line)\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', full_model.f_test('(Treatment[T.NCM]=0), (Treatment[T.NCM]:k=0)'))\n",
    "print(f\"    LR: Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(k_model, Tandk_model)\n",
    "print('k vs T+k')\n",
    "print(\"--------\")\n",
    "print(\"We are testing if a model of the learning curves that includes a lesion treatment (2 parallel lines) is a better fit than one without (1 line)\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', Tandk_model.f_test('(Treatment[T.NCM]=0)'))\n",
    "print(f\"    LR: Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(T_model, full_model)\n",
    "print('T vs full')\n",
    "print(\"--------\")\n",
    "print(\"We are testing if a model of the learning curves that includes informative trials (2 lines with slopes) is a better fit than one without slope (2 horizontal lines)\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', full_model.f_test('(k=0), (Treatment[T.NCM]:k=0)'))\n",
    "print(f\"    LR: Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(null_model, T_model)\n",
    "print('Null vs T')\n",
    "print('---------')\n",
    "print(\"We are testing if a model of the learning curves that includes Treatment (2 horizontal lines) is a better fit than one without treatment (1 horizontal line)\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', T_model.f_test('(Treatment[T.NCM]=0)'))\n",
    "print(f\"    LR: Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "pvalue, x, dof = likelihood_ratio_test(Tandk_model, full_model)\n",
    "print('T+k vs full')\n",
    "print('---------')\n",
    "print(\"We are testing if a model of the learning curves that includes Treatment and k (2 arbitrary lines) is a better fit than one without 2 parallel lines\")\n",
    "print()\n",
    "print(\"Result:\")\n",
    "print('     f-test:', full_model.f_test('(Treatment[T.NCM]:k=0)'))\n",
    "print(f\"    Chi2({dof}) = {x:.2f}, {parse_p(pvalue)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k model did not converge, but the full model converged.  Thus we used the f-test using the results from the full model instead of the likelihood ratio test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This figure is not part of the paper\n",
    "# Just to visualize the data we are fitting to investigate the non-convergence\n",
    "for subj, subjdf in learning_curve_logors.groupby(\"Subject\"):\n",
    "    plt.plot(np.arange(11), subjdf[\"logOR\"], color=COLORMAP[subjdf.iloc[0][\"Treatment\"]])\n",
    "    plt.xlabel(\"k\", fontsize=16)\n",
    "    plt.ylabel(\"logOR\", fontsize=16)\n",
    "plt.title(\"Learning curves for each individual subject\", fontsize=16)\n",
    "border(plt.gca(), 1, 0, 0, 1)\n",
    "plt.show()\n",
    "plt.close(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5C (now on second row of 4C)\n",
    "# First we measure the magnitude of performance after lesion for k <= 10 (this can be 10 or 3 see above)\n",
    "print(\"Magnitude of postlesion performance on S2 in the k <= 10 window\")\n",
    "for treatment, post_data in [(\"NCM\", post_ncm), (\"HVC\", post_hvc), (\"CTRL\", post_ctrl), (\"HVC+CTRL\", post_hvc_and_ctrl)]:\n",
    "    logor = np.mean(post_data[\"logOR\"])\n",
    "    ttest_result = scipy.stats.ttest_1samp(post_data[\"logOR\"], 0)\n",
    "    print(f\" {treatment}: logOR = {logor:.2f}, t({len(post_data) - 1}) = {ttest_result.statistic:.2f}, {parse_p(ttest_result.pvalue)}\")\n",
    "\n",
    "print()\n",
    "print(\"The following two tests look for a difference between the groups\")\n",
    "print(\"1. ANOVA to test for a difference across the three groups\")\n",
    "print(\"2. Sample sizes matched by combining HVC+CTRL (n=11) to NCM (n=10) and doing a normal t-test\")\n",
    "print()\n",
    "\n",
    "# ANOVA and Tukeys post-hoc test for differences in postlesion logOR for k <= 3\n",
    "anova_result = anova_oneway(\n",
    "    post[\"logOR\"],\n",
    "    groups=post[\"Treatment\"],\n",
    "    use_var=\"equal\",\n",
    ")\n",
    "print(\"1. ANOVA result\")\n",
    "print(\"------------\")\n",
    "print(\" A significant difference between the groups was not detected\")\n",
    "print(f\"  F({anova_result.df_num}, {anova_result.df_denom}) = {anova_result.statistic:.2f}; {parse_p(anova_result.pvalue)}\")\n",
    "print()\n",
    "tukey = pairwise_tukeyhsd(\n",
    "    endog=post[\"logOR\"],\n",
    "    groups=post[\"Treatment\"],\n",
    "    alpha=0.05)\n",
    "print(tukey)\n",
    "print()\n",
    "\n",
    "# NCM vs HVC+CTRL\n",
    "print(\"2. Direct comparison between the (sample size matched) NCM and combined HVC+CTRL\")\n",
    "print(\"-----------------------------------------------------------------------------------\")\n",
    "ttest_result = scipy.stats.ttest_ind(post_ncm[\"logOR\"], post_hvc_and_ctrl[\"logOR\"])\n",
    "print(f\" {treatment}: t({len(post_ncm) + len(post_hvc_and_ctrl) - 2}) = {ttest_result.statistic:.2f}, {parse_p(ttest_result.pvalue)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s2d2_data(ax: plt.Axes = None, k_max = 11):\n",
    "    \"\"\"Generates a table of post-lesion logOR\n",
    "    \"\"\"\n",
    "    post_data = []\n",
    "    \n",
    "    # k_array = tuple(np.arange(K_MAX_INITIAL + 1))  # The values of k to compute over\n",
    "\n",
    "    k_array = tuple(np.arange(k_max))  # The values of k to compute over\n",
    "    for treatment in [\"NCM\", \"HVC\", \"CTRL\"]:\n",
    "        tsvk_post = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"postlesion\")\n",
    "            & (df.VocalizerSet == \"S2\")\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "            & df.LadderStage.isin([\"DCvsDC_6v6_d2_S2\", \"SovsSo_8v8_d2_S2\"])\n",
    "        ], k_max = k_max)\n",
    "        \n",
    "        logor_data = tsvk_post.logOR_by_subjects(k=k_array)\n",
    "        logor_data[\"Treatment\"] = treatment\n",
    "        \n",
    "        post_data.append(logor_data)\n",
    "\n",
    "\n",
    "    tsvk_post = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"postlesion\")\n",
    "        & (df.VocalizerSet == \"S2\")\n",
    "        & df.SubjectTreatment.isin([\"HVC\", \"CTRL\"])\n",
    "        & df.LadderStage.isin([\"DCvsDC_6v6_d2_S2\", \"SovsSo_8v8_d2_S2\"])\n",
    "    ], k_max = k_max)\n",
    "\n",
    "    logor_data = tsvk_post.logOR_by_subjects(k=k_array)\n",
    "    logor_data[\"Treatment\"] = \"HVC+CTRL\"\n",
    "    post_data.append(logor_data)\n",
    "\n",
    "    return pd.concat(post_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = s2d2_data(k_max = 1001)\n",
    "\n",
    "post_ncm = post[post[\"Treatment\"] == \"NCM\"]\n",
    "post_hvc = post[post[\"Treatment\"] == \"HVC\"]\n",
    "post_ctrl = post[post[\"Treatment\"] == \"CTRL\"]\n",
    "post_hvc_and_ctrl = post[post[\"Treatment\"] == \"HVC+CTRL\"]\n",
    "post = post[post[\"Treatment\"] != \"HVC+CTRL\"]\n",
    "\n",
    "print(\"Magnitude of postlesion performance on S2 for day 2\")\n",
    "for treatment, post_data in [(\"NCM\", post_ncm), (\"HVC\", post_hvc), (\"CTRL\", post_ctrl), (\"HVC+CTRL\", post_hvc_and_ctrl)]:\n",
    "    logor = np.mean(post_data[\"logOR\"])\n",
    "    ttest_result = scipy.stats.ttest_1samp(post_data[\"logOR\"], 0)\n",
    "    print(f\" {treatment}: logOR = {logor:.2f}, t({len(post_data) - 1}) = {ttest_result.statistic:.2f}, {parse_p(ttest_result.pvalue)}\")\n",
    "\n",
    "print()\n",
    "print(\"The following two tests look for a difference between the groups\")\n",
    "print(\"1. ANOVA to test for a difference across the three groups\")\n",
    "print(\"2. Sample sizes matched by combining HVC+CTRL (n=11) to NCM (n=10) and doing a normal t-test\")\n",
    "print()\n",
    "\n",
    "# ANOVA and Tukeys post-hoc test for differences in postlesion logOR \n",
    "anova_result = anova_oneway(\n",
    "    post[\"logOR\"],\n",
    "    groups=post[\"Treatment\"],\n",
    "    use_var=\"equal\",\n",
    ")\n",
    "print(\"1. ANOVA result\")\n",
    "print(\"------------\")\n",
    "print(\" A significant difference between the groups was not detected\")\n",
    "print(f\"  F({anova_result.df_num}, {anova_result.df_denom}) = {anova_result.statistic:.2f}; {parse_p(anova_result.pvalue)}\")\n",
    "print()\n",
    "tukey = pairwise_tukeyhsd(\n",
    "    endog=post[\"logOR\"],\n",
    "    groups=post[\"Treatment\"],\n",
    "    alpha=0.05)\n",
    "print(tukey)\n",
    "print()\n",
    "\n",
    "# NCM vs HVC+CTRL\n",
    "print(\"2. Direct comparison between the (sample size matched) NCM and combined HVC+CTRL\")\n",
    "print(\"-----------------------------------------------------------------------------------\")\n",
    "ttest_result = scipy.stats.ttest_ind(post_ncm[\"logOR\"], post_hvc_and_ctrl[\"logOR\"])\n",
    "print(f\" {treatment}: t({len(post_ncm) + len(post_hvc_and_ctrl) - 2}) = {ttest_result.statistic:.2f}, {parse_p(ttest_result.pvalue)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = s2d2_data(k_max = 51)\n",
    "\n",
    "post_ncm = post[post[\"Treatment\"] == \"NCM\"]\n",
    "post_hvc = post[post[\"Treatment\"] == \"HVC\"]\n",
    "post_ctrl = post[post[\"Treatment\"] == \"CTRL\"]\n",
    "post_hvc_and_ctrl = post[post[\"Treatment\"] == \"HVC+CTRL\"]\n",
    "post = post[post[\"Treatment\"] != \"HVC+CTRL\"]\n",
    "\n",
    "print(\"Magnitude of postlesion performance on S2 for day 2\")\n",
    "for treatment, post_data in [(\"NCM\", post_ncm), (\"HVC\", post_hvc), (\"CTRL\", post_ctrl), (\"HVC+CTRL\", post_hvc_and_ctrl)]:\n",
    "    logor = np.mean(post_data[\"logOR\"])\n",
    "    ttest_result = scipy.stats.ttest_1samp(post_data[\"logOR\"], 0)\n",
    "    print(f\" {treatment}: logOR = {logor:.2f}, t({len(post_data) - 1}) = {ttest_result.statistic:.2f}, {parse_p(ttest_result.pvalue)}\")\n",
    "\n",
    "print()\n",
    "print(\"The following two tests look for a difference between the groups\")\n",
    "print(\"1. ANOVA to test for a difference across the three groups\")\n",
    "print(\"2. Sample sizes matched by combining HVC+CTRL (n=11) to NCM (n=10) and doing a normal t-test\")\n",
    "print()\n",
    "\n",
    "# ANOVA and Tukeys post-hoc test for differences in postlesion logOR \n",
    "anova_result = anova_oneway(\n",
    "    post[\"logOR\"],\n",
    "    groups=post[\"Treatment\"],\n",
    "    use_var=\"equal\",\n",
    ")\n",
    "print(\"1. ANOVA result\")\n",
    "print(\"------------\")\n",
    "print(\" A significant difference between the groups was not detected\")\n",
    "print(f\"  F({anova_result.df_num}, {anova_result.df_denom}) = {anova_result.statistic:.2f}; {parse_p(anova_result.pvalue)}\")\n",
    "print()\n",
    "tukey = pairwise_tukeyhsd(\n",
    "    endog=post[\"logOR\"],\n",
    "    groups=post[\"Treatment\"],\n",
    "    alpha=0.05)\n",
    "print(tukey)\n",
    "print()\n",
    "\n",
    "# NCM vs HVC+CTRL\n",
    "print(\"2. Direct comparison between the (sample size matched) NCM and combined HVC+CTRL\")\n",
    "print(\"-----------------------------------------------------------------------------------\")\n",
    "ttest_result = scipy.stats.ttest_ind(post_ncm[\"logOR\"], post_hvc_and_ctrl[\"logOR\"])\n",
    "print(f\" {treatment}: t({len(post_ncm) + len(post_hvc_and_ctrl) - 2}) = {ttest_result.statistic:.2f}, {parse_p(ttest_result.pvalue)}\")\n",
    "\n",
    "# Effect size\n",
    "meanNCM = np.mean(post_ncm[\"logOR\"])\n",
    "meanCTRL = np.mean(post_hvc_and_ctrl[\"logOR\"])\n",
    "    \n",
    "# normalization term\n",
    "nNCM = len(post_ncm.index)\n",
    "nCTRL = len(post_hvc_and_ctrl.index)\n",
    "varNCM = np.var(post_ncm[\"logOR\"]) \n",
    "varCTRL = np.var(post_hvc_and_ctrl['logOR'])\n",
    "norm_var = np.sqrt((varNCM * nNCM + varCTRL * nCTRL) / (nNCM + nCTRL-2))\n",
    "\n",
    "# effect size of NCM lesion on memory\n",
    "d_prime = (np.sqrt(2) * (meanCTRL-meanNCM)) / norm_var\n",
    "\n",
    "print(f\"Effect size d\\'={d_prime:.2f} Mean NCM={meanNCM:.2f} Mean HVC+CTRL={meanCTRL:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        tsvk_post = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"postlesion\")\n",
    "            & (df.VocalizerSet == \"S2\")\n",
    "            & (df.SubjectTreatment == 'NCM')\n",
    "            & df.LadderStage.isin([\"DCvsDC_6v6_d2_S2\", \"SovsSo_8v8_d2_S2\"])\n",
    "        ], k_max = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped_df = tsvk_post.df.groupby(\"Subject\") \n",
    "maximums = grouped_df.max() \n",
    "maximums = maximums.reset_index()\n",
    "print(maximums['Subject'], maximums['RelInformativeTrialsSeen'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xomhdFpMAwz_"
   },
   "source": [
    "## Figure 6\n",
    "\n",
    "Plotting the overall performance on new (S2) stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tIVIkNZqW-H"
   },
   "outputs": [],
   "source": [
    "def figure_6(treatment: str, call_type: str = None, ax: plt.Axes = None):\n",
    "    \"\"\"Plot the overall odds ratios when the stimuli are well learned\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    colormap = {\n",
    "        \"NCM\": NCM_COLOR,\n",
    "        \"HVC\": HVC_COLOR,\n",
    "        \"CTRL\": CTRL_COLOR\n",
    "    }\n",
    "    \n",
    "    if call_type is None:\n",
    "        call_type_filter = np.ones_like(df.StimulusCallType).astype(bool)\n",
    "    else:\n",
    "        call_type_filter = df.StimulusCallType == call_type\n",
    "\n",
    "    tsvk_S1_pre = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"prelesion\")\n",
    "        & (df.VocalizerSet == \"S1\")\n",
    "        & (df.SubjectTreatment == treatment)\n",
    "        & call_type_filter\n",
    "        & df.LadderStage.isin([\"DCvsDC_6v6_d2\", \"SovsSo_8v8_d2\"])\n",
    "    ])\n",
    "    tsvk_S1_post = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"postlesion\")\n",
    "        & (df.VocalizerSet == \"S1\")\n",
    "        & (df.SubjectTreatment == treatment)\n",
    "        & call_type_filter\n",
    "        & df.LadderStage.isin([\"DCvsDC_6v6_d2\", \"SovsSo_8v8_d2\"])\n",
    "    ])\n",
    "    tsvk_S2_post = get_or_create_Tsvk(df[\n",
    "        (df.LesionStage == \"postlesion\")\n",
    "        & (df.VocalizerSet == \"S2\")\n",
    "        & (df.SubjectTreatment == treatment)\n",
    "        & call_type_filter\n",
    "        & df.LadderStage.isin([\"DCvsDC_6v6_d2_S2\", \"SovsSo_8v8_d2_S2\"])\n",
    "    ])\n",
    "        \n",
    "    scores_1 = tsvk_S1_pre.fisher_exact_by_subjects(side=\"greater\")\n",
    "    scores_2 = tsvk_S1_post.fisher_exact_by_subjects(side=\"greater\")\n",
    "    scores_3 = tsvk_S2_post.fisher_exact_by_subjects(side=\"greater\")\n",
    "    \n",
    "    mean_1 = np.mean(scores_1[\"logOR\"])\n",
    "    mean_2 = np.mean(scores_2[\"logOR\"])\n",
    "    mean_3 = np.mean(scores_3[\"logOR\"])\n",
    "    \n",
    "    sem_1 = np.std(scores_1[\"logOR\"]) / np.sqrt(len(scores_1))\n",
    "    sem_2 = np.std(scores_2[\"logOR\"]) / np.sqrt(len(scores_2))\n",
    "    sem_3 = np.std(scores_3[\"logOR\"]) / np.sqrt(len(scores_3))\n",
    "\n",
    "    ax.plot([0, 1, 2], np.array([scores_1[\"logOR\"], scores_2[\"logOR\"], scores_3[\"logOR\"]]), alpha=1, linewidth=1, color=\"0.8\")\n",
    "\n",
    "    ax.scatter(0 * np.ones(len(scores_1)), scores_1[\"logOR\"], s=3, linewidth=1, alpha=1, facecolor=\"none\", edgecolor=\"0.8\")\n",
    "    ax.scatter(1 * np.ones(len(scores_2)), scores_2[\"logOR\"], s=3, linewidth=1, alpha=1, facecolor=\"none\", edgecolor=\"0.8\")\n",
    "    ax.scatter(2 * np.ones(len(scores_3)), scores_3[\"logOR\"], s=3, linewidth=1, alpha=1, facecolor=\"none\", edgecolor=\"0.8\")\n",
    "    \n",
    "    dof = len(scores_1) - 1\n",
    "\n",
    "    print(\" Paired t-test results to see if scores after lesion were different than before lesion:\")\n",
    "    print(\"  S1' - S1\")\n",
    "    tstat, pvalue = scipy.stats.ttest_rel(scores_2[\"logOR\"], scores_1[\"logOR\"], alternative='two-sided')\n",
    "    diff = np.mean(scores_2['logOR'] - scores_1['logOR'])\n",
    "    dprime = np.sqrt(2)*diff/np.std(scores_2['logOR'] - scores_1['logOR'])\n",
    "    print(f\"   t({dof}) = {tstat:.2f}, {parse_p(pvalue)}\")\n",
    "    print(f\"   diff = {diff:.2f}\")\n",
    "    print(f\"   d-prime = {dprime:.2f}\")\n",
    "    \n",
    "    print(\"  S2' - S1\")\n",
    "    tstat, pvalue = scipy.stats.ttest_rel(scores_3[\"logOR\"], scores_1[\"logOR\"], alternative='two-sided')\n",
    "    diff = np.mean(scores_3['logOR'] - scores_1['logOR'])\n",
    "    dprime = np.sqrt(2)*diff/np.std(scores_3['logOR'] - scores_1['logOR'])\n",
    "    print(f\"   t({dof}) = {tstat:.2f}, {parse_p(pvalue)}\")\n",
    "    print(f\"   diff = {diff:.2f}\")\n",
    "    print(f\"   d-prime = {dprime:.2f}\")\n",
    "    \n",
    "    print()\n",
    "    print(\" One-sample t-test for logOR > 0:\")\n",
    "    dof = len(scores_1) - 1\n",
    "    print(\"  S1\")\n",
    "    tstat, pvalue = scipy.stats.ttest_1samp(scores_1[\"logOR\"], 0, alternative=\"greater\")\n",
    "    print(f\"   logOR = {np.mean(scores_1['logOR']):.2f}, t({dof}) = {tstat:.2f}, {parse_p(pvalue)}\")\n",
    "\n",
    "    print(\"  S1'\")\n",
    "    dof = len(scores_2) - 1\n",
    "    tstat, pvalue = scipy.stats.ttest_1samp(scores_2[\"logOR\"], 0, alternative=\"greater\")\n",
    "    print(f\"   logOR = {np.mean(scores_2['logOR']):.2f}, t({dof}) = {tstat:.2f}, {parse_p(pvalue)}\")\n",
    "\n",
    "    print(\"  S2'\")\n",
    "    dof = len(scores_3) - 1\n",
    "    tstat, pvalue = scipy.stats.ttest_1samp(scores_3[\"logOR\"], 0, alternative=\"greater\")\n",
    "    print(f\"   logOR = {np.mean(scores_3['logOR']):.2f}, t({dof}) = {tstat:.2f}, {parse_p(pvalue)}\")\n",
    "\n",
    "    print()\n",
    "    ax.errorbar(\n",
    "        [0.1, 1.1, 2.1], \n",
    "        [mean_1, mean_2, mean_3], \n",
    "        2 * np.array([sem_1, sem_2, sem_3]),\n",
    "        linewidth=1.5, markersize=4, markerfacecolor=\"white\", color=colormap[treatment], marker=\"d\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pyc2DosWqXAi"
   },
   "outputs": [],
   "source": [
    "fig = figure_cm(COL1 - 1, 4, dpi=300)\n",
    "axes = fig.subplots(1, 3)\n",
    "\n",
    "print(\" NCM\")\n",
    "print(\"--------\")\n",
    "figure_6(\"NCM\", ax=axes[0])\n",
    "\n",
    "print(\" HVC\")\n",
    "print(\"--------\")\n",
    "figure_6(\"HVC\", ax=axes[1])\n",
    "\n",
    "print(\" CTRL\")\n",
    "print(\"--------\")\n",
    "figure_6(\"CTRL\", ax=axes[2])\n",
    "\n",
    "for ax in axes:\n",
    "    border(ax, 1)\n",
    "    ax.set_xlim(-0.5, 2.5)\n",
    "\n",
    "for ax in axes:\n",
    "    draw_logor_axes_markers(smallest=-2, biggest=8, convert_log=False, ax=ax)\n",
    "    ax.set_ylim(-1, 10)\n",
    "    border(ax, 1)\n",
    "    \n",
    "for ax in axes[1:]:\n",
    "    border(ax)\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "for ax in axes[1:]:\n",
    "    ax.tick_params(labelleft=False)\n",
    "\n",
    "axes[0].set_ylabel(\"$OR$\", fontsize=8)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticks(\n",
    "        [0, 1, 2],\n",
    "        [\"S1\", \"S1$^\\dagger$\", \"S2$^\\dagger$\"],\n",
    "        rotation=45,\n",
    "        fontsize=6)\n",
    "\n",
    "if SAVE_FIGS:\n",
    "    fig.savefig(savedir(\"fig6.svg\"), format=\"svg\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7\n",
    "\n",
    "Lesion size analysis on memory effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_summary_table = load_lesion_summary_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lesion_size(subject):\n",
    "    if np.any(lesion_summary_table.Subject == subject):\n",
    "        return lesion_summary_table[lesion_summary_table.Subject == subject].iloc[0][\"TotalVolume (mm^3)\"]\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_7(call_type: str, ax: plt.Axes = None):\n",
    "    \"\"\"Create a scatter plot between NCM lesion size and change in logOR before and after lesion\n",
    "    \n",
    "    Also fit a best fit line just to the NCM points\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    for treatment in [\"NCM\", \"HVC\", \"CTRL\"]:\n",
    "        tsvk_S1_pre = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"prelesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & (df.StimulusCallType == call_type)\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "            & df.LadderStage.isin([\"DCvsDC_6v6_d2\", \"SovsSo_8v8_d2\"])\n",
    "        ])\n",
    "        tsvk_S1_post = get_or_create_Tsvk(df[\n",
    "            (df.LesionStage == \"postlesion\")\n",
    "            & (df.VocalizerSet == \"S1\")\n",
    "            & (df.StimulusCallType == call_type)\n",
    "            & (df.SubjectTreatment == treatment)\n",
    "            & df.LadderStage.isin([\"DCvsDC_6v6_d2\", \"SovsSo_8v8_d2\"])\n",
    "        ])\n",
    "        \n",
    "        scores_1 = tsvk_S1_pre.fisher_exact_by_subjects(side=\"greater\")\n",
    "        scores_2 = tsvk_S1_post.fisher_exact_by_subjects(side=\"greater\")\n",
    "        assert np.all(scores_1[\"Subject\"] == scores_2[\"Subject\"])\n",
    "        delta = scores_2[\"logOR\"] - scores_1[\"logOR\"]\n",
    "        \n",
    "        lesion_sizes = [get_lesion_size(subject) for subject in scores_1[\"Subject\"]]\n",
    "        \n",
    "        ax.scatter(\n",
    "            lesion_sizes,\n",
    "            delta,\n",
    "            s=30,\n",
    "            linewidth=1,\n",
    "            facecolor=\"none\",\n",
    "            label=treatment,\n",
    "            edgecolor=COLORMAP[treatment]\n",
    "        )\n",
    "        \n",
    "        if treatment == \"NCM\":\n",
    "            x_data = lesion_sizes\n",
    "            y_data = delta\n",
    "\n",
    "            x_data = sm.add_constant(x_data)\n",
    "            result = statsmodels.regression.linear_model.OLS(y_data, x_data)\n",
    "            r = np.corrcoef(x_data[:, 1], y_data)[0, 1]\n",
    "            result = result.fit()\n",
    "            print(f\"Best fit line to NCM data ({call_type})\")\n",
    "            print(\"-------------------------\")\n",
    "            \n",
    "            print(f\" r = {r:.2f}, F({result.df_model:.0f}, {result.df_resid:.0f}) = {result.fvalue:.2f} {parse_p(result.f_pvalue)}, R2_adj = {result.rsquared_adj:.2f}\")\n",
    "            print()\n",
    "            \n",
    "            x = np.linspace(-0.1, 1.1, num=3)\n",
    "            ax.plot(x, result.params[0] + result.params[1] * x, linewidth=1, color=NCM_COLOR, linestyle=\"--\", zorder=-1)\n",
    "\n",
    "            pvalue = result.pvalues[1]\n",
    "            r2_adj = result.rsquared_adj\n",
    "            ax.text(\n",
    "                0.04,\n",
    "                0.02, \n",
    "                \"$R^2_{adj}$\" + f\"={r2_adj:.2f}\\n\" + \"$p=$\" + f\"{pvalue:.2f}\",\n",
    "                fontsize=8, \n",
    "                verticalalignment=\"bottom\",\n",
    "                horizontalalignment=\"left\",\n",
    "                color=NCM_COLOR,\n",
    "                transform=ax.transAxes\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the slopes of the lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure_cm(COL1_5 - 1, 5, dpi=300)\n",
    "\n",
    "print()\n",
    "axes = fig.subplots(1, 2, sharey=True)#  gridspec_kw={\"hspace\": 1.0})\n",
    "figure_7(\"SO\", ax=axes[0])\n",
    "figure_7(\"DC\", ax=axes[1])\n",
    "\n",
    "axes[0].set_ylabel(r\"$\\frac{OR^{\\dagger}}{OR}$\", fontsize=10, verticalalignment=\"center\", rotation=0)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim(-0.1, 1.1)\n",
    "    border(ax, 1, 0, 0, 1)\n",
    "    draw_logor_axes_markers(smallest=-7, biggest=2, convert_log=False, ax=ax)\n",
    "    ax.set_ylim(-7, 2.4)\n",
    "    ax.set_xticks([0, 0.5, 1.0], [0, 0.5, 1.0], fontsize=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.supxlabel(\"NCM Lesion Volume ($mm^3$)\", fontsize=8)\n",
    "\n",
    "if SAVE_FIGS:\n",
    "    fig.savefig(savedir(\"fig7.svg\"), format=\"svg\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PaperFigures3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
